
<!-- saved from url=(0051)https://computing.llnl.gov/tutorials/parallel_comp/ -->
<html><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<title>Вступ до паралельних обчислень</title>

<script language="JavaScript" src="./Introduction to Parallel Computing_files/tutorials.js.Без названия"></script>
<link rel="StyleSheet" href="./Introduction to Parallel Computing_files/tutorials.css" type="text/css">
<link rel="SHORTCUT ICON" href="http://www.llnl.gov/favicon.ico">

<!-- BEGIN META TAGS -->
<meta name="LLNLRandR" content="UCRL-MI-133316">
<meta name="distribution" content="global">
<meta name="description" content="Livermore Computing Training">
<meta name="rating" content="general">
<meta http-equiv="keywords" content="Lawrence Livermore
National Laboratory, LLNL, High Performance Computing, parallel, programming, 
HPC, training, workshops, tutorials, Blaise Barney">
<meta name="copyright" content="This document is copyrighted U.S.
Department of Energy">
<meta name="Author" content="Blaise Barney">
<meta name="email" content="blaiseb@llnl.gov">
<!-- END META TAGS -->
</head>

<body>
<basefont size="3">            <!-- default font size -->
<font face="arial">

<!-- Begin Piwik Tracking Code  -->
<script src="./Introduction to Parallel Computing_files/piwik.js.Без названия" type="text/javascript">
</script>
<script>
var siteName = 1-.domain;
var pkBaseURL = 'https://analytics.llnl.gov/';
if (typeof jQuery=="undefined") {
    document.write(unescape("%3Cscript src='" + pkBaseURL + "jquery.js' type='text/javascript'%3E%3C/script%3E"));
}
</script><script src="./Introduction to Parallel Computing_files/jquery.js.Без названия" type="text/javascript"></script>
<script>
    try {
        var LLNLTracker = Piwik.getTracker(pkBaseURL + "piwik.php", 1);
        LLNLTracker.trackPageView();
        LLNLTracker.enableLinkTracking();
        var localSiteTracker = Piwik.getTracker(pkBaseURL + "piwik.php", 149);
        localSiteTracker.trackPageView();
        localSiteTracker.enableLinkTracking();
    }
    catch (err) {
        console.log(err);
    }
</script><noscript><p><img src="https://analytics.llnl.gov/piwik.php?idsite=149" style="border:0" alt="" /></p></noscript>
<!-- End Piwik Tracking Code -->

<a name="top">  </a>
<table cellpadding="0" cellspacing="0" width="100%">
<tbody><tr><td colspan="2" bgcolor="#3F5098">
  <table cellpadding="0" cellspacing="0" width="900">
  <tbody><tr><td background="./Introduction to Parallel Computing_files/bg1.gif">
  <a name="top"> </a>
  <script language="JavaScript">addNavigation()</script>   <table border="0"><tbody><tr align="center" valign="center">    <td><font size="-1" face="arial">    <a href="https://computing.llnl.gov/training#training_materials">Навчальні посібники</a></font></td>    <td><b>|</b></td>   <td><font size="-1" face="arial">    <a href="https://computing.llnl.gov/tutorials/exercises/index.html">Вправи</a></font></td>    <td><b>|</b></td>   <td><font size="-1" face="arial">    <a href="https://computing.llnl.gov/tutorials/abstracts/index.html">Реферати</a></font></td>    <td><b>|</b></td>   <td><font size="-1" face="arial">    <a href="https://computing.llnl.gov/training#workshops">Магазин робіт</a></font></td>    <td><b>|</b></td>   <td><font size="-1" face="arial">    <a href="https://computing.llnl.gov/tutorials/misc/comments.html">Коментарі</a></font></td>    <td><b>|</b></td>   <td><font size="-1" face="arial">    <a href="https://computing.llnl.gov/tutorials/search/index.html">Пошук</a></font></td>    <td><b>|</b></td>   <td><font size="-1" face="arial">   <a href="http://www.llnl.gov/disclaimer.html" target="W2">   Конфіденційність</a></font></td>   </tr></tbody></table>   
  <p><br>
  </p><h1>Вступ до паралельних обчислень</h1>
  <p>
  </p></td></tr></tbody></table>
</td>
</tr><tr valign="top">
<td><i>Автори: Блейз Барні, Національна лабораторія ім. Лоуренса Лівермора</i></td>
<td align="right"><font size="-1">UCRL-MI-133316</font></td>
</tr></tbody></table>
<p>

<a name="TOC"> </a>
</p><h2>Зміст</h2>
<ol>
<li><a href="https://computing.llnl.gov/tutorials/parallel_comp/#Abstract">Навчальні посібники</a>
</li><li><a href="https://computing.llnl.gov/tutorials/parallel_comp/#Overview">Огляд</a>
    <ol>
    <li><a href="https://computing.llnl.gov/tutorials/parallel_comp/#Whatis">Що таке паралельні обчислення?</a>
    </li><li><a href="https://computing.llnl.gov/tutorials/parallel_comp/#WhyUse">Навіщо використовувати паралельні обчислення?</a>
    </li><li><a href="https://computing.llnl.gov/tutorials/parallel_comp/#Who">Хто використовує паралельні обчислення?</a>
    </li></ol>

</li><li><a href="https://computing.llnl.gov/tutorials/parallel_comp/#Concepts">Поняття та термінології</a>
    <ol>
    <li><a href="https://computing.llnl.gov/tutorials/parallel_comp/#Neumann">Архітектурою комп'ютерної системи Неймана</a>
    </li><li><a href="https://computing.llnl.gov/tutorials/parallel_comp/#Flynn">Класична таксономія Флінна</a>
    </li><li><a href="https://computing.llnl.gov/tutorials/parallel_comp/#Terminology">Деяка загальна паралельна термінологія</a>
    </li><li><a href="https://computing.llnl.gov/tutorials/parallel_comp/#LimitsCosts">Межі та витрати паралельного програмування</a> 
</li></ol>

</li><li><a href="https://computing.llnl.gov/tutorials/parallel_comp/#MemoryArch">Паралельні архітектури пам'яті комп'ютера</a> 
    <ol>
    <li><a href="https://computing.llnl.gov/tutorials/parallel_comp/#SharedMemory">Спільна пам'ять</a> 
    </li><li><a href="https://computing.llnl.gov/tutorials/parallel_comp/#DistributedMemory">Розподілена пам'ять</a> 
    </li><li><a href="https://computing.llnl.gov/tutorials/parallel_comp/#HybridMemory">Гібридна розподілена загальна пам'ять</a>
    </li></ol>
 
</li><li><a href="https://computing.llnl.gov/tutorials/parallel_comp/#Models">Моделі паралельного програмування</a>
    <ol>
    <li><a href="https://computing.llnl.gov/tutorials/parallel_comp/#ModelsOverview">Огляд</a>
    </li><li><a href="https://computing.llnl.gov/tutorials/parallel_comp/#ModelsShared">Модель спільної пам'яті</a> 
    </li><li><a href="https://computing.llnl.gov/tutorials/parallel_comp/#ModelsThreads">Моделі ниток</a>
    </li><li><a href="https://computing.llnl.gov/tutorials/parallel_comp/#ModelsMessage">Модель пропущеної пам'яті / повідомлення</a>
    </li><li><a href="https://computing.llnl.gov/tutorials/parallel_comp/#ModelsData">Паралельна модель даних</a>
    </li><li><a href="https://computing.llnl.gov/tutorials/parallel_comp/#Hybrid">Гібридна модель</a>
    </li><li><a href="https://computing.llnl.gov/tutorials/parallel_comp/#SPMD-MPMD">SPMD та MPMP</a>
    </li></ol>

</li><li><a href="https://computing.llnl.gov/tutorials/parallel_comp/#Designing">Розробка паралельних програм</a>
    <ol>
    <li><a href="https://computing.llnl.gov/tutorials/parallel_comp/#DesignAutomatic">Автоматична або паралелізація вручну</a>
    </li><li><a href="https://computing.llnl.gov/tutorials/parallel_comp/#DesignUnderstand">Зрозуміння проблем та програм</a>
    </li><li><a href="https://computing.llnl.gov/tutorials/parallel_comp/#DesignPartitioning">Розбиття</a> 
    </li><li><a href="https://computing.llnl.gov/tutorials/parallel_comp/#DesignCommunications">Зв'язок</a> 
    </li><li><a href="https://computing.llnl.gov/tutorials/parallel_comp/#DesignSynchronization">Синхронізація</a>
    </li><li><a href="https://computing.llnl.gov/tutorials/parallel_comp/#DesignDependencies">Залежності даних</a>
    </li><li><a href="https://computing.llnl.gov/tutorials/parallel_comp/#DesignLoadBalance">Балансування навантаження</a> 
    </li><li><a href="https://computing.llnl.gov/tutorials/parallel_comp/#DesignGranularity">Гранулярність</a> 
    </li><li><a href="https://computing.llnl.gov/tutorials/parallel_comp/#DesignIO">I/O</a>
    </li><li><a href="https://computing.llnl.gov/tutorials/parallel_comp/#DesignDebug">Налагодження</a>
    </li><li><a href="https://computing.llnl.gov/tutorials/parallel_comp/#DesignPerformance">Аналіз продуктивності та настройка</a>
    </li></ol>

</li><li><a href="https://computing.llnl.gov/tutorials/parallel_comp/#Examples">Паралельні приклади</a> 
    <ol>
    <li><a href="https://computing.llnl.gov/tutorials/parallel_comp/#ExamplesArray">Обробка масивів</a>
    </li><li><a href="https://computing.llnl.gov/tutorials/parallel_comp/#ExamplesPI">Розрахунок PI</a> 
    </li><li><a href="https://computing.llnl.gov/tutorials/parallel_comp/#ExamplesHeat">Просте рівняння тепла</a> 
    </li><li><a href="https://computing.llnl.gov/tutorials/parallel_comp/#ExamplesWave">1-D хвильове рівняння</a>
    </li></ol>

</li><li><a href="https://computing.llnl.gov/tutorials/parallel_comp/#References">Довідники та додаткова інформація</a>
</li></ol>
 
<!--========================================================================-->
 
<a name="Abstract"> <br><br> </a>
<table border="1" cellpadding="5" cellspacing="0" width="100%">
<tbody><tr><td bgcolor="#98ABCE">
<span class="heading1">Навчальні посібники</span></td>
</tr></tbody></table>
<p><br>
 
Це перший навчальний посібник у семінарі "Лівермор Комп'ютер". Він має на меті забезпечити лише дуже короткий огляд широкої та широкої теми паралельних обчислень, як провідний для підручників, які слідують за нею. Таким чином, він охоплює лише основи паралельних обчислень і призначений для того, хто просто хочу ознайомиться з предметом і хто планує відвідувати один або декілька інших підручників у цьому семінарі. Він не має на меті поширювати глибоке паралельне програмування, оскільки це вимагатиме значно більше часу. Навчальний посібник починається з обговорення паралельних обчислень - що це таке, як він використовується, а потім обговорення концепцій та термінів, пов'язаних з паралельними обчисленнями. Потім досліджуються теми архітектур паралельної пам'яті та моделей програмування. За цими темами йде низка практичних обговорень з ряду складних питань, пов'язаних із розробкою та виконанням паралельних програм. Підручник завершується декількома прикладами паралелізації простих серійних програм.
<br><br>

<!--========================================================================-->

<a name="Overview"> <br><br> </a>
<a name="Whatis"> </a>
<table border="1" cellpadding="5" cellspacing="0" width="100%">
<tbody><tr><td bgcolor="#98ABCE">
<span class="heading1">Огляд</span></td>
</tr></tbody></table>
</p><h2>Що таке паралельні обчислення?</h2>

<img src="./Introduction to Parallel Computing_files/arrowBullet.gif" align="top" hspace="3">
<span class="heading3">Серійний обчислення:</span>
<ul>
<p>
</p><li>Традиційно для  <b><i>серійного</i></b>  обчислення було написано програмне забезпечення:
    <ul>
    <li>Проблема розбита на дискретну серію інструкцій
    </li><li>Інструкції виконуються послідовно один за одним
    </li><li>Виконано на одному процесорі
    </li><li>Тільки одна команда може виконуватись в будь-який момент часу
    </li></ul>
<p>
<img src="./Introduction to Parallel Computing_files/serialProblem.gif" width="604" height="250" border="1" alt="Serial computing">
</p><p>
<b>Наприклад:</b>
</p><p>
<img src="./Introduction to Parallel Computing_files/serialProblem2.gif" width="604" height="250" border="1" alt="Serial computing">
</p></li></ul>
<p>

<img src="./Introduction to Parallel Computing_files/arrowBullet.gif" align="top" hspace="3">
<span class="heading3">Паралельні обчислення:</span>
</p><ul>
<li>У найпростішому сенсі, <b><i>паралельні обчислення</i></b> - це одночасне використання кількох обчислювальних ресурсів для вирішення обчислювальної задачі:
    <ul>
    <li>Проблема розбита на окремі частини, які можна вирішити одночасно
    </li><li>Кожна частина далі розбита на ряд інструкцій
    </li><li>Інструкції з кожної частини виконуються одночасно на різних процесорах
    </li><li>Використовується загальний механізм контролю / координації
    </li></ul>
<p>
<img src="./Introduction to Parallel Computing_files/parallelProblem.gif" width="683" height="372" border="1" alt="Parallel computing">
</p><p>
<b>Наприклад:</b>
</p><p>
<img src="./Introduction to Parallel Computing_files/parallelProblem2.gif" width="683" height="372" border="1" alt="Parallel computing">
</p><p>
</p></li><li>Обчислювальна проблема повинна бути в змозі:
    <ul>
    <li>Розбиті на окремі частини задачі, які можна вирішити одночасно;
    </li><li>Виконати декілька інструкцій програми в будь-який момент часу;
    </li><li>Вирішуватиметься в менший проміжок часу за допомогою кількох обчислювальних ресурсів, ніж з єдиним обчислювальним ресурсом.
    </li></ul>
<p>
</p></li><li>Обчислювальні ресурси зазвичай:
    <ul>
    <li>Єдиний комп'ютер з декількома процесорами / ядрами
    </li><li>Довільне число таких комп'ютерів, з'єднаних мережею
    </li></ul>
</li></ul>
<p>

<img src="./Introduction to Parallel Computing_files/arrowBullet.gif" align="top" hspace="3">
<span class="heading3">Паралельні комп'ютери:</span>
</p><ul>
<p>
</p><li>Практично всі автономні комп'ютери сьогодні паралельні з апаратної перспективи:
    <ul>
    <li>Кілька функціональних одиниць (кеш L1, кеш-пам'ять L2, гілка, попередня вибірка, декодування, плаваюча кома, обробка графіки (графічне зображення), ціле число тощо).
    </li><li>Кілька одиниць виконання / ядер
    </li><li>Кілька апаратних ниток
    </li></ul>
<p>
<table border="0" cellspacing="0" cellpadding="0">
<tbody><tr valign="top">
<td align="center">
<img src="./Introduction to Parallel Computing_files/bgqComputeChip.jpg" width="450" heigth="453">
<br>IBM BG / Q Compute Chip з 18 ядер (PU) і 16 одиниць кеш-пам'яті L2 (L2)</td>
</tr></tbody></table>
</p><p>
</p></li><li>Мережі підключають декілька автономних комп'ютерів (вузлів) для створення більших паралельних комп'ютерних кластерів.
<p>
<img src="./Introduction to Parallel Computing_files/nodesNetwork.gif" width="720" heigth="249">
</p><p>
</p></li><li>Наприклад, на схемі нижче показано типовий паралельний кластер LLNL
    <ul>
    <li>Кожен обчислювальний вузол сам по собі є багатопроцесорним паралельним комп'ютером
    </li><li>Кілька обчислювальних вузлів мережа разом з мережею Infiniband
    </li><li>Вузли спеціального призначення, також багатопроцесорні, використовуються для інших цілей
    </li></ul>
<p>
<img src="./Introduction to Parallel Computing_files/parallelComputer1.gif" width="781" heigth="402">
</p><p>
</p></li><li>Більшість великих паралельних комп'ютерів у світі (суперкомп'ютерів) - це кластери апаратного забезпечення, створені декількома (в основному) відомими постачальниками.
<p>
<img src="./Introduction to Parallel Computing_files/top500Vendors.png">
<br><font size="-1"><i>Джерело: <a href="http://top500.org/" target="_blank">Top500.org</a></i></font>
</p></li></ul>

<!--========================================================================-->

<a name="WhyUse"> <br><br> </a>
<table border="1" cellpadding="5" cellspacing="0" width="100%">
<tbody><tr><td bgcolor="#98ABCE">
<span class="heading1">Огляд</span></td>
</tr></tbody></table>
<h2>Навіщо використовувати паралельні обчислення?</h2>

<img src="./Introduction to Parallel Computing_files/arrowBullet.gif" align="top" hspace="3">
<span class="heading3">Реальний світ масово паралельно:</span>
<p>
<table border="0" cellspacing="0" cellpadding="0" width="800">
<tbody><tr valign="top">
<td>
<ul>
<li>У природному світі багато складних, взаємопов'язаних подій відбуваються одночасно, але всередині тимчасової послідовності.
<p>
</p></li><li>Порівняно з послідовним обчисленням, паралельні обчислення набагато краще підходять для моделювання, моделювання та розуміння складних, реальних явищ.
<p>
</p></li><li>Наприклад, уявімо собі, як моделювати їх послідовно:
<p>
<img src="./Introduction to Parallel Computing_files/realWorldCollage1.jpg" width="760" height="220">
<br><img src="./Introduction to Parallel Computing_files/realWorldCollage2.jpg" width="760" height="230">
<br><img src="./Introduction to Parallel Computing_files/realWorldCollage3.jpg" width="760" height="208">
</p></li></ul>
</td>
</tr></tbody></table>


<img src="./Introduction to Parallel Computing_files/arrowBullet.gif" align="top" hspace="3">
<span class="heading3">Основні причини:</span>

</p><p>
<table border="0" cellpadding="0" cellspacing="0" width="700">
<tbody><tr valign="top">
<td><ul>
<li><b>Зберегти час і гроші:</b> 
    <ul>
    <li>Теоретично, викидаючи більше ресурсів на завдання, скорочується час до завершення, з можливістю економії коштів.
    </li><li>Паралельні комп'ютери можуть бути побудовані з дешевих, товарних компонентів.
    <p>
    <img src="./Introduction to Parallel Computing_files/timeMoney2.jpg" width="600" height="182">
    </p></li></ul>
<p>
</p></li><li><b>РОЗШИРЕННЯ ВЕЛИКИХ /  КОМПЛЕКСНИХ ПРОБЛЕМ:</b> 
    <ul>
    <li>Багато проблем настільки великі та / або складні, що непрактично або неможливо їх вирішити на одному комп'ютері, особливо з обмеженою комп'ютерною пам'яттю.
    </li><li>Приклад: "Проблеми великих викликів 
        (<a href="http://en.wikipedia.org/wiki/Grand_Challenge" target="_blank">en.wikipedia.org/wiki/Grand_Challenge</a>), що вимагають використання PetaFLOPS та PetaBytes обчислювальних ресурсів.
    </li><li>Приклад: веб-пошукові машини / бази даних, що обробляють мільйони транзакцій кожну секунду.
    <p>
    <img src="./Introduction to Parallel Computing_files/biggerProblems.jpg" width="600" height="180">
    </p></li></ul>
<p>
</p></li><li><b>Впровадження паралельності:</b> 
    <ul>
    <li>Один обчислювальний ресурс може робити лише одну річ за раз. Кілька обчислювальних ресурсів можуть робити багато речей одночасно.
    </li><li>Приклад: спільні мережі забезпечують глобальне місце, де люди з усього світу можуть зустрічатися та працювати "практично".
    <p>
    <img src="./Introduction to Parallel Computing_files/collaborativeNetworks.jpg" width="600" height="182">
    </p></li></ul>
<p>
</p></li><li><b>ЗАСТОСОВУВАТИ ПЕРЕВАГУ НЕЛОКАЛЬНИХ РЕСУРСІВ:</b> 
    <ul>
    <li>Використання обчислювальних ресурсів у широкосмуговій мережі або навіть в Інтернеті, коли локальні обчислювальні ресурси є дефіцитними або недостатніми. Нижче наведено два приклади, у кожному з яких понад 1,7 мільйонів учасників у глобальному масштабі (травень 2018 року):
    </li><li>Приклад: SETI @ home (<a href="http://setiathome.berkeley.edu/" target="_blank">setiathome.berkeley.edu</a>)        <!------------ Source:
        <A HREF=https://boincstats.com/ TARGET=_blank>
        https://boincstats.com/</A> 
        -------------->
    </li><li>Приклад: Folding @ home (<a href="http://folding.stanford.edu/" target="folding">folding.stanford.edu</a>)
    <p>
    <img src="./Introduction to Parallel Computing_files/SETILogo.jpg" width="600" height="122">
    </p></li></ul>
<p>
</p></li><li><b>ЗРОБИТИ ВИКОРИСТАННЯ ПАРАМЕТРОВОГО ОБЛАДНАННЯ:</b> 
    <ul>
    <li>Сучасні комп'ютери, навіть ноутбуки, є паралельними в архітектурі з декількома процесорами / ядрами.
    </li><li>Паралельне програмне забезпечення спеціально призначене для паралельних апаратних засобів з декількома ядрами, нитками тощо.
    </li><li>У більшості випадків серійні програми запускають на сучасних комп'ютерах "відходи" потенціалу обчислювальної потужності.
    <p>
    <table border="0" cellspacing="0" cellpadding="0">
    <tbody><tr valign="top">
    <td align="center">
    <img src="./Introduction to Parallel Computing_files/xeon5600processorDie3.jpg" width="600" height="321">
    <br>Процесор Intel Xeon з 6 ядер та 6 одиниць кеш-пам'яті L3</td>
    </tr></tbody></table>
    </p></li></ul>
</li></ul>
<p>

<img src="./Introduction to Parallel Computing_files/arrowBullet.gif" align="top" hspace="3">
<span class="heading3">Майбутнє:</span>
</p><ul>
<li>Протягом останніх 20 років тенденції, що свідчать про все більш швидкі мережі, розподілені системи та багатопроцесорні комп'ютерні архітектури (навіть на рівні робочого столу), ясно показують, що <b><i>паралелізм - це майбутнє обчислень.</i></b>.
<p>
</p></li><li>У цей же період часу спостерігалося збільшення продуктивності суперкомп'ютера більш ніж на
    <font style="background-color: yellow"><b>500 000 хв</b></font>, 
   і в даний час не існує кінця.
<p>
</p></li><li><b><i>Гонка вже працює на Exascale Computing!</i></b>
    <ul>
    <li>Exaflop = 10<sup>18</sup> розрахунків за секунду
    </li></ul>
</li></ul>
<p>
<img src="./Introduction to Parallel Computing_files/top500.1993-2018.png">
</p><dd><font size="-1"><i>Джерело: <a href="http://top500.org/" target="_blank">Top500.org</a></i></font>
</dd></td>
</tr></tbody></table>

<!--========================================================================-->

<a name="Who"> <br><br> </a>
<table border="1" cellpadding="5" cellspacing="0" width="100%">
<tbody><tr><td bgcolor="#98ABCE">
<span class="heading1">Огляд</span></td>
</tr></tbody></table>
</p><h2>Хто використовує паралельні обчислення?</h2>

<p>
<table border="0" cellspacing="0" cellpadding="0" width="800">
<tbody><tr valign="top">
<td>
<img src="./Introduction to Parallel Computing_files/arrowBullet.gif" align="top" hspace="3">
<span class="heading3">Наука та техніка:</span>
<ul>
<li>Історично склалося так, що паралельні обчислення вважаються "високим кінцем обчислень", і були використані для моделювання складних проблем у багатьох галузях науки та техніки:
<table border="0" cellspacing="0" cellpadding="0">
<tbody><tr valign="top">
<td><ul>
    <li>Атмосфера, Земля, навколишнє середовище
    </li><li>ФФізика - прикладна, ядерна, частинка, конденсована речовина, високий тиск, синтез, фотоніка
    </li><li>Біологія, Біотехнологія, Генетика
    </li><li>Хімія, молекулярні науки
    </li><li>Геологія, сейсмологія
    </li></ul></td>
<td><ul>
    <li>Машинобудування - від протезування до космічних апаратів
    </li><li>Електротехніка, схемотехніка, мікроелектроніка
    </li><li>Комп'ютерні науки, математика
    </li><li>Оборона, зброя
    </li></ul></td>
</tr></tbody></table>
<p>
<img src="./Introduction to Parallel Computing_files/simulations01.jpg" width="781" height="357">
</p></li></ul>
<p>

<img src="./Introduction to Parallel Computing_files/arrowBullet.gif" align="top" hspace="3">
<span class="heading3">Промислові та комерційні</span>
</p><ul>
<li>Сьогодні комерційні додатки забезпечують однакову або більшу рушійну силу при розробці більш швидких комп'ютерів. Ці програми вимагають обробки великої кількості даних за допомогою складних способів. Наприклад:
<table border="0" cellspacing="0" cellpadding="0">
<tbody><tr valign="top">
<td><ul>
    <li>"Big Data", бази даних, виведення даних
    </li><li>Штучний інтелект (AI)
    </li><li>Веб-пошукові системи, веб-сервіси
    </li><li>Медична візуалізація та діагностика
    </li><li>Фармацевтичний дизайн
    </li></ul></td>
<td><ul>
    <li>Фінансове та економічне моделювання
    </li><li>Управління національними та мультинаціональними корпораціями 
    </li><li>Розвинена графіка та віртуальна реальність, особливо в індустрії розваг
    </li><li>Мережеві відео та мультимедійні технології
    </li><li>Пошук нафти
    </li></ul></td>
</tr></tbody></table>
<p>
<img src="./Introduction to Parallel Computing_files/simulations03.jpg" width="781" height="360">
</p></li></ul>
</td>
</tr></tbody></table>

<img src="./Introduction to Parallel Computing_files/arrowBullet.gif" align="top" hspace="3">
<span class="heading3">Глобальні програми:</span>
</p><ul>
<li>Паралельні обчислення в даний час широко використовуються у всьому світі, у різних областях застосування.
<p>
<img src="./Introduction to Parallel Computing_files/top500Apps.gif" width="753" height="446"><br><font size="-1"><i>Джерело: <a href="http://top500.org/" target="_blank">Top500.org</a></i></font><p>
</p><table border="0" cellpadding="0" cellspacing="0">
<tbody><tr valign="top">


<td colspan="2">
Натисніть на зображення нижче для більшої версії</td>
</tr><tr valign="top">
<td><a href="./Introduction to Parallel Computing_files/top500SegmentsTime.png" target="_blank">
<img src="./Introduction to Parallel Computing_files/top500SegmentsTime.png" width="400"></a></td>
<td><a href="./Introduction to Parallel Computing_files/top500CountriesTime.png">
<img src="./Introduction to Parallel Computing_files/top500CountriesTime.png" target="_blank" width="400"></a></td>
</tr></tbody></table>
<br><font size="-1"><i>Джерело: <a href="http://top500.org/" target="_blank">Top500.org</a></i></font>
</p></li></ul>

<!--========================================================================-->

<a name="Concepts"> <br><br> </a>
<a name="Neumann"> </a>
<table border="1" cellpadding="5" cellspacing="0" width="100%">
<tbody><tr><td bgcolor="#98ABCE">
<span class="heading1">Поняття та термінологія</span></td>
</tr></tbody></table>
<h2>за архітектурою Неймана</h2>

<ul>
<p>
</p><li>Названий за угорським математиком / генієм Джоном фон Нейманом, який вперше створив загальні вимоги до електронного комп'ютера в своїх 1945-х роботах.
<p>
</p></li><li>Також відомий як "Накопичувач програма" - як інструкції програми, так і дані зберігаються в електронній пам'яті.
<p>
</p></li><li>З тих пір практично всі комп'ютери дотримуються цього базового дизайну:
   
</li></ul>
<p>
<table cellpadding="0" cellspacing="0">
<tbody><tr valign="top">
<td><img src="./Introduction to Parallel Computing_files/vonNeumann1.gif" width="293" height="277"></td>
<td><ul>
<li>Складається з чотирьох основних компонентів:
    <ul>
    <li>Пам'ять
    </li><li>Пристрій управління
    </li><li>Арифметичний логічний блок
    </li><li>Введення-виведення
    </li></ul>
<p>
</p></li><li>Читання / запис, пам'ять випадкового доступу використовується для зберігання як програмних інструкцій, так і даних
    <ul>
    <li>Програмні інструкції - це закодовані дані, які повідомляють комп'ютеру щось зробити
    </li><li>Дані - це просто інформація, яка буде використовуватися програмою
    </li></ul>
<p>
</p></li><li>Блок керування виводить інструкції / дані з пам'яті, декодує інструкції, а потім <b><i>послідовно</i></b> координує операції для виконання запрограмованого завдання.
<p>
</p></li><li>Арифметичний підрозділ виконує базові арифметичні операції
<p>
</p></li><li>Вхід / вихід є інтерфейсом для оператора людини
</li></ul></td>
<td align="center"><img src="./Introduction to Parallel Computing_files/vonNeumann2.jpg" width="221" height="287" hspace="20">
<br><i>Джон фон Нейман близько 1940-х років<br>(Джерело: архіви LANL)</i></td>
</tr></tbody></table>
</p><p>
</p><ul>
<p>
</p><li>Більше інформації про його інші чудові досягнення:
    <a href="http://en.wikipedia.org/wiki/John_von_Neumann" target="_blank">
    http://en.wikipedia.org/wiki/John_von_Neumann</a>
<p>
</p></li><li>І що? Хто хвилює? 
    <ul>
    <li>Що ж, паралельні комп'ютери все ще дотримуються цього базового дизайну, просто помножуючись на одиниці. Основна, фундаментальна архітектура залишається незмінною.
    </li></ul>
</li></ul>

<!--========================================================================-->
<p>
<a name="Flynn"> <br><br> </a>
<table border="1" cellpadding="5" cellspacing="0" width="100%">
<tbody><tr><td bgcolor="#98ABCE">
<span class="heading1">Поняття та термінологія</span></td>
</tr></tbody></table>
</p><h2>Класична таксономія Флінна</h2>

<ul>
<li>Існують різні способи класифікації паралельних комп'ютерів. Приклади доступні
    <a href="https://computing.llnl.gov/tutorials/parallel_comp/parallelClassifications.pdf" target="_blank">ТУТ</a>. 
<p>
</p></li><li>Один з найбільш широко використовуваних класифікацій, що використовуються з 1966 року, називається таксономією Філліна.
<p>
</p></li><li>Таксономія Флінна розрізняє багатопроцесорні комп'ютерні архітектури відповідно до того, як їх можна класифікувати за двома незалежними вимірами <b><i>потоку інструкцій</i></b> та <b><i>потоку даних</i></b>.  
   Кожен з цих параметрів може мати лише один із двох можливих станів
    <b><i>Одиночний </i></b> or <b><i>Кілька</i></b>.
<p>
</p></li><li>Матриця нижче визначає 4 можливих класифікацій відповідно до Flynn:
<p>
<img src="./Introduction to Parallel Computing_files/flynnsTaxonomy.gif" width="425">
</p></li></ul>

<p><br></p><hr><p><br>

<img src="./Introduction to Parallel Computing_files/arrowBullet.gif" align="top" hspace="3">
<span class="heading3">Єдина інструкція, єдині дані (SISD):</span>
</p><ul>
<li>Серійний (не паралельний) комп'ютер
</li><li><b>Єдина інструкція:</b> ЦП використовує лише один потік інструкцій протягом будь-якого циклу годин
</li><li><b>Окремі дані:</b> лише один потік даних використовується як вхід протягом будь-якого циклу годинника
</li><li>Детерміноване виконання   
</li><li>Це найстаріший тип комп'ютера
</li><li>Приклади: мейнфрейми старшого покоління, мікрокомп'ютери, робочі станції та ПК з одним процесором / ядром.
<p>

<table border="0" cellpadding="5" cellspacing="3" bgcolor="#EEEEEE" width="975"> 
<tbody><tr valign="top" align="center">
<td align="left"><img src="./Introduction to Parallel Computing_files/sisd2.gif" height="224" border="1" hspace="30"></td>
<td> </td>
<td><img src="./Introduction to Parallel Computing_files/sisd.gif" width="188" height="224"></td>
</tr><tr valign="top" align="center">
<td><img src="./Introduction to Parallel Computing_files/univac1.LLNL.200pix.jpg" width="262" height="200">
<br><b>UNIVAC1	</b></td>
<td><img src="./Introduction to Parallel Computing_files/ibm.360.200pix.jpg" width="300" height="200">
<br><b>IBM 360</b></td>
<td><img src="./Introduction to Parallel Computing_files/cray1.LLNL.200pix.jpg" width="200" height="200">
<br><b>CRAY1</b></td>
</tr><tr valign="top" align="center">
<td><img src="./Introduction to Parallel Computing_files/cdc7600.LLNL.200pix.jpg" width="262" height="200">
<br><b>CDC 7600</b></td>
<td><img src="./Introduction to Parallel Computing_files/pdp1.LLNL.200pix.jpg" width="298" height="200">
<br><b>PDP1</b></td>
<td><img src="./Introduction to Parallel Computing_files/dellLaptop.200pix.jpg" width="201" height="200">
<br><b>Dell Laptop</b></td>
</tr></tbody></table>
</p></li></ul>

<p><br></p><hr><p><br>

<img src="./Introduction to Parallel Computing_files/arrowBullet.gif" align="top" hspace="3">
<span class="heading3">Одна інструкція, кілька видів даних (SIMD):</span>
</p><ul>
<li>Тип паралельного комп'ютера
</li><li><b>Одинична інструкція:</b>  всі процесори виконують одну й ту ж інструкцію в будь-якому заданому циклі годин
</li><li><b>Кілька даних:</b> кожен процесор може працювати на іншому елементі даних.
</li><li>Найкраще підходять для спеціалізованих проблем, що характеризуються високим рівнем регулярності, такими як обробка графіки / зображення.
</li><li>Синхронний (локальний) і детермінований виконання.
</li><li>Два різновиди: масив процесора та векторні трубопроводи
</li><li>Приклади: 
    <ul type="circle">
    <li>Масив процесора: мишачі машини CM-2, MasPar MP-1 і MP-2, ILLIAC IV
    </li><li>Векторні трубопроводи: IBM 9000, Cray X-MP, Y-MP і C90, Fujitsu VP, NEC SX-2, Hitachi S820, ETA10
    </li></ul>
</li><li>Більшість сучасних комп'ютерів, особливо ті, що мають графічні процесорні блоки (графічні процесори), використовують команди SIMD та виконавчі пристрої.
<p>

<table border="0" cellpadding="5" cellspacing="3" bgcolor="#EEEEEE" width="975"> 
<tbody><tr valign="top" align="center">
<td><img src="./Introduction to Parallel Computing_files/simd3.gif" height="224" border="1"></td>
<td> </td>
<td><img src="./Introduction to Parallel Computing_files/simd.gif" width="438" height="224"></td>
</tr><tr valign="top" align="center">
<td><img src="./Introduction to Parallel Computing_files/illiacIV.200pix.jpg" width="293" height="200">
<br><b>ILLIAC IV</b></td>
<td><img src="./Introduction to Parallel Computing_files/MasPar.200pix.jpg" width="172" height="200">
<br><b>MasPar</b></td>
<td><br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
<img src="./Introduction to Parallel Computing_files/simd2.gif" width="400" height="147" border="0"></td>
</tr></tbody></table>
<table border="0" cellpadding="5" cellspacing="3" bgcolor="#EEEEEE" width="975"> 
<tbody><tr valign="top" align="center">
<td><img src="./Introduction to Parallel Computing_files/crayXMP.200pix.jpg" width="150" height="200">
<br><b>Cray X-MP</b></td>
<td><img src="./Introduction to Parallel Computing_files/crayYMP.200pix.jpg" width="282" height="200">
<br><b>Cray Y-MP</b></td>
<td><img src="./Introduction to Parallel Computing_files/cm2.200pix.jpg" width="298" height="200">
<br><b>Thinking Machines CM-2</b></td>
<td><img src="./Introduction to Parallel Computing_files/cellProcessor.200pix.jpg" width="179" height="200">
<br><b>Cell Processor (GPU)</b></td>
</tr></tbody></table>
</p></li></ul>

<p><br></p><hr><p><br>

<img src="./Introduction to Parallel Computing_files/arrowBullet.gif" align="top" hspace="3">
<span class="heading3">Кілька інструкцій, одиночні дані (MISD):</span>
</p><ul>
<li>Тип паралельного комп'ютера
</li><li><b>Кілька інструкцій:</b> кожен процесор працює на даних самостійно за допомогою окремих потоків інструкцій.
</li><li><b>Окремі дані:</b> єдиний потік даних подається на кілька модулів обробки.
</li><li>Мало (якщо такі є) фактичні приклади цього класу паралельних комп'ютерів коли-небудь існували.
</li><li>Деякі мислимі способи використання можуть бути:
    <ul>
    <li>кілька фільтрів частоти, що працюють на одному сигналі потоку
    </li><li>кілька алгоритмів криптографії, що намагаються зламати єдине кодоване повідомлення.
    </li></ul>
<p>

<table border="0" cellpadding="5" cellspacing="3" bgcolor="#EEEEEE" width="975"> 
<tbody><tr valign="center" align="center">
<td align="left"><img src="./Introduction to Parallel Computing_files/misd4.gif" height="245" hspace="30" border="1"></td>
<td><img src="./Introduction to Parallel Computing_files/misd.gif" width="438" height="207" hspace="20"></td>
</tr></tbody></table>
</p></li></ul>

<p></p><hr><p>

<img src="./Introduction to Parallel Computing_files/arrowBullet.gif" align="top" hspace="3">
<span class="heading3">Кілька інструкцій, кілька даних (MIMD):</span>
</p><ul>
<li>Тип паралельного комп'ютера.
</li><li><b>Кілька інструкцій:</b> кожен процесор може виконувати інший потік інструкцій.
</li><li><b>Кілька даних:</b> кожен процесор може працювати з різним потоком даних.
</li><li>Виконання може бути синхронним або асинхронним, детермінованим або недетермінованим.
</li><li>В даний час найпоширеніший тип паралельного комп'ютера - найсучасніші суперкомп'ютери потрапляють до цієї категорії.
</li><li>Приклади: найбільш сучасні суперкомп'ютери, мережеві паралельні комп'ютерні кластери та "сітки", багатопроцесорні комп'ютери SMP, багатоядерні ПК.
</li><li>Примітка. Багато MIMD-архітектури також включають підкомпоненти виконання SIMD.
<p>

<table border="0" cellpadding="5" cellspacing="3" bgcolor="#EEEEEE" width="975"> 
<tbody><tr valign="top" align="center">
<td><img src="./Introduction to Parallel Computing_files/mimd2.gif" height="245" border="1"></td>
<td colspan="2"><img src="./Introduction to Parallel Computing_files/mimd.gif" width="438" height="245"></td>
</tr><tr valign="top" align="center">
<td><img src="./Introduction to Parallel Computing_files/ibmPower5Cluster.200pix.jpg" width="301" height="200">
<br><b>IBM POWER5</b></td>
<td><img src="./Introduction to Parallel Computing_files/alphaserverCluster.200pix.jpg" width="302" height="200">
<br><b>HP/Compaq Alphaserver</b></td>
<td><img src="./Introduction to Parallel Computing_files/ia32Cluster.200pix.jpg" width="299" height="200">
<br><b>Intel IA32</b></td>
</tr></tbody></table>
<table border="0" cellpadding="5" cellspacing="3" bgcolor="#EEEEEE" width="975"> 
<tbody><tr valign="top" align="center">
<td><img src="./Introduction to Parallel Computing_files/opteronCluster.200pix.jpg" width="299" height="200">
<br><b>AMD Opteron</b></td>
<td><img src="./Introduction to Parallel Computing_files/crayXT3Cluster.200pix.jpg" width="300" height="200">
<br><b>Cray XT3</b></td>
<td><img src="./Introduction to Parallel Computing_files/bglCluster.200pix.jpg" width="301" height="200">
<br><b>IBM BG/L</b></td>
</tr></tbody></table>
</p></li></ul>
<p>

<!--========================================================================-->

<a name="Terminology"> <br><br> </a>
<table border="1" cellpadding="5" cellspacing="0" width="100%">
<tbody><tr><td bgcolor="#98ABCE">
<span class="heading1">Поняття та термінологія</span></td>
</tr></tbody></table>
</p><h2>Деяка загальна паралельна термінологія</h2>

<ul>
<li>Як і все інше, паралельні обчислення мають свій "жаргон". Нижче наведено деякі з найпоширеніших термінів, пов'язаних з паралельними обчисленнями.
<p>
</p></li><li>Більшість з них буде обговорюватися більш детально пізніше.<p>
</p><dl>
<dt><b>Суперкомп'ютерне / високопродуктивне обчислення (HPC)</b>
</dt><dd>Використання найшвидших і найбільших комп'ютерів у світі для вирішення великих проблем.
<p>
</p></dd><dt><b>Вузол </b>
</dt><dd>Автономний "комп'ютер в коробці". Зазвичай складається з декількох процесорів / процесорів / ядер, пам'яті, мережевих інтерфейсів тощо. Вузли об'єднуються в мережу для створення суперкомп'ютера.
<p>
</p></dd><dt><b>CPU / Socket / Процесор / Core </b>
</dt><dd>Це залежить від того, з чим ви працюєте. У минулому процесор (центральний процесор) був єдиним компонентом виконання для комп'ютера. Потім декілька процесорів були включені в вузол. Потім, окремі процесори були  розділені на кілька "ядер", кожен з яких є унікальним блоком виконання. Процесори з декількома ядрами іноді називають "сокетами" - залежними від постачальників. Результатом є вузол з декількома процесорами, кожен із яких містить декілька ядер. Номенклатура заплутана часом. Чудово чому?
<p>
<img src="./Introduction to Parallel Computing_files/nodeSocketCores.jpg" width="800" heigth="375">
</p><p>
</p></dd><dt><b>Завдання </b>
</dt><dd>Логічно дискретний розділ обчислювальних робіт. Завдання, як правило, являє собою програмний або програмний набір інструкцій, який виконується процесором. Паралельна програма складається з декількох завдань, що виконуються на декількох процесорах.
<p>
</p></dd><dt><b>Трубопроводи</b>
</dt><dd>Розбиваючи завдання на кроки, виконувані різними блоками процесора, з вхідними потоками через, як схожу лінію; тип паралельних обчислень.
<p>
</p></dd><dt><b>Спільна пам'ять</b>
</dt><dd>З суто апаратної точки зору, описується архітектура комп'ютера, де всі процесори мають прямий (звичайний) доступ до загальної фізичної пам'яті. У програмуванні він описує модель, в якій паралельні завдання мають однакову "картинку" пам'яті і можуть безпосередньо звертатися до одних і тих же логічних місць пам'яті незалежно від того, де фактично існує фізична пам'ять.
<p>
</p></dd><dt><b>Симметричний багатопроцесор (SMP)</b>
</dt><dd>Архітектура апаратного забезпечення спільної пам'яті, де кілька процесорів мають єдиний адресний простір і мають рівний доступ до всіх ресурсів.
<p>
</p></dd><dt><b>Розподілена пам'ять</b>
</dt><dd>У апаратному забезпеченні розуміється доступ до пам'яті на мережевому рівні для фізичної пам'яті, який не є загальним. Як модель програмування завдання можуть логічно "бачити" локальну пам'ять комп'ютера і використовувати комунікації для доступу до пам'яті на інших машинах, де виконуються інші завдання.
<p>
</p></dd><dt><b>Зв'язок</b>
</dt><dd>Паралельні завдання зазвичай потребують обміну даними. Це може бути досягнуто кількома способами, наприклад, через спільну пам'ять або через мережу, проте фактична подія обміну даними часто називається зв'язком, незалежно від використовуваного методу.
<p>
</p></dd><dt><b>Синхронізація</b>
</dt><dd>Координація паралельних завдань у режимі реального часу, дуже часто пов'язана з комунікаціями. Часто реалізується шляхом встановлення точки синхронізації в додатку, де завдання може не продовжуватися, доки інші завдання (и) не досягнуть тієї ж або логічно еквівалентної точки.
<p>
Синхронізація зазвичай передбачає очікування як мінімум одного завдання, і тому може призвести до збільшення часу виконання часу настінного годинника паралельної програми.
</p><p>
</p></dd><dt><b>Гранулярність</b>
</dt><dd>При паралельних обчисленнях деталізація є якісною мірою співвідношення обчислень до комунікації.
    <ul>
    <li><b><i>Грубі:</i></b> відносно великі обсяги обчислювальних робіт виконуються між комунікаційними подіями.
    </li><li><b><i>Добре:</i></b> відносно невеликі обсяги обчислювальних робіт виконуються між подій зв'язку.
    </li></ul>
<p></p></dd><dt><b>Спостерігається прискорення</b>
</dt><dd>Спостерігається прискорення розпаралелювання коду, який визначається як:
<p>
<table border="1" cellpadding="5" cellspacing="0">
<tbody><tr><td align="center">
<pre>настінний час послідовного виконання

-----------------------------------
 настінний час паралельного виконання</pre></td>
</tr></tbody></table>
</p><p>
Один з найпростіших і найбільш широко використовуваних показників для виконання паралельної програми.
</p><p>
</p></dd><dt><b>Паралельні накладні витрати</b>
</dt><dd>Кількість часу, необхідного для координації паралельних завдань, на відміну від здійснення корисної роботи. Паралельні накладні витрати можуть включати наступні фактори:
    <ul>
    <li>Час запуску завдання
    </li><li>Синхронізація
    </li><li>Передача даних
    </li><li>Накладне програмне забезпечення, накладене паралельними мовами, бібліотеками, операційною системою тощо.
    </li><li>Час завершення завдання
    </li></ul>
<p>
</p></dd><dt><b>Масовано паралельно</b>
</dt><dd>Належить до апаратного забезпечення, що складається з заданої паралельної системи, що має багато оброблюваних елементів. Значення "багатьох" постійно зростає, але в даний час найбільші паралельні комп'ютери складаються з оброблюваних елементів, що нумерують від сотень тисяч до мільйонів.
<p>
</p></dd><dt><b>Смутно паралельно</b> 
</dt><dd>Рішення багатьох аналогічних, але незалежних завдань одночасно; трохи не потребує координації між завданнями.
<p>
</p></dd><dt><b>Масштабованість</b>
</dt><dd>Посилається на здатність паралельної системи (обладнання та / або програмне забезпечення) демонструвати пропорційне збільшення паралельного прискорення з додаванням більшої кількості ресурсів. Фактори, що сприяють масштабованості, включають:
    <ul>
    <li>Апаратне забезпечення - особливо пропускна спроможність пам'яті-процесор та властивості мережевого зв'язку
    </li><li>Алгоритм застосування
    </li><li>Паралельні накладні витрати пов'язані
    </li><li>Характеристики вашої конкретної програми
    </li></ul>
</dd></dl>
</li></ul>

<!--========================================================================-->

<a name="LimitsCosts"> <br><br> </a>
<table border="1" cellpadding="5" cellspacing="0" width="100%">
<tbody><tr><td bgcolor="#98ABCE">
<span class="heading1">Поняття та термінологія</span></td>
</tr></tbody></table>
<h2>Межі та витрати паралельного програмування</h2>

<img src="./Introduction to Parallel Computing_files/arrowBullet.gif" align="top" hspace="3">
<span class="heading3">Закон Амдаля:</span>
<p>
<table cellpadding="0" cellspacing="0" width="100%">
<tbody><tr valign="top">
<td><ul>
<p>
</p><li><b>Закон Амдаля</b> говорить про те, що потенціал прискорення програми визначається часткою коду (P), яку можна розпаралелювати:
<p>
<table border="1" cellspacing="0" cellpadding="5">
<tbody><tr valign="top"><td><pre><b>
                     1
    прискорення = -------- 
                   1  - P

</b></pre></td></tr></tbody></table>
</p><p>
</p></li><li>Якщо жоден з блоків коду не може бути розпаралелізований, P = 0 і прискорення = 1 (без прискорення).
<p>
</p></li><li>Якщо весь код розпаралелюється, P = 1 і прискорення є нескінченним (теоретично).
<p>
</p></li><li>Якщо 50% коду можна розпаралелювати, максимальна швидкість = 2, тобто код буде працювати вдвічі швидше.
<p>
</p></li><li>Представляючи кількість процесорів, що виконують паралельну частку роботи, співвідношення можна моделювати за допомогою:
<p>
<table border="1" cellspacing="0" cellpadding="5">
<tbody><tr valign="top"><td><pre><b>
                       1  
    прискорення =  ------------ 
                    P   +  S
                   ---
                    N

</b></pre></td></tr></tbody></table>
</p><p>
   де P = паралельна фракція, N = кількість процесорів і S = серійна фракція.
</p></li></ul>
</td>
<td><img src="./Introduction to Parallel Computing_files/amdahl1.gif" width="509" height="390" border="1" hspace="20">
<br>
<img src="./Introduction to Parallel Computing_files/amdahl2.gif" width="509" height="391" border="1" hspace="20"></td>
</tr></tbody></table>
</p><p>
</p><ul>
<li>Незабаром стає очевидним, що існують межі масштабованості паралелізму. Наприклад: 
<p>
<table border="1" cellspacing="0" cellpadding="5">
<tbody><tr valign="top"><td><pre><b>
                       прискоритись
          -------------------------------------
    N     P = .50   P = .90   P = .95   P = .99
  -----   -------   -------   -------   -------
     10      1.82      5.26      6.89      9.17
    100      1.98      9.17     16.80     50.25     
  1,000      1.99      9.91     19.62     90.99
 10,000      1.99      9.91     19.96     99.02
100,000      1.99      9.99     19.99     99.90

</b></pre></td></tr></tbody></table>
</p><p>
<b>"Знаменитий" вираз:</b><i> Ви можете витратити на все життя 95% вашого коду, щоб бути паралельним, і ніколи не досягти прискорення краще, ніж 20x незалежно від того, скільки процесорів ви кидаєте на це!

</i>
</p></li></ul>

<ul>
<p>
</p><li>Проте деякі проблеми демонструють підвищену продуктивність, збільшуючи розмір проблеми. Наприклад
<p>
<table border="1" cellspacing="0" cellpadding="5">
<tbody><tr valign="top"><td><pre><b>
    2D Grid Calculations     85 seconds   85%    
    Serial fraction          15 seconds   15%    

</b></pre></td></tr></tbody></table>
</p><p>
   Ми можемо збільшити розмір проблеми, подвоївши розміри сітки та зменшивши наполовину часовий крок. Це призводить до чотирикратного збільшення кількості точок сітки та вдвічі більшої кількості етапів часу. Тоді танфіни виглядають так:
</p><p>
<table border="1" cellspacing="0" cellpadding="5">
<tbody><tr valign="top"><td><pre><b>
    2D Grid Calculations     680 seconds   97.84%    
    Serial fraction           15 seconds    2.16%    

</b></pre></td></tr></tbody></table>
</p><p>
</p></li><li>Проблеми, що збільшують відсоток паралельного часу з їх розміром, більш <b><i>масштабні</i></b> ніж проблеми з фіксованою процентною часткою паралельного часу.
</li></ul>
<p>

<img src="./Introduction to Parallel Computing_files/arrowBullet.gif" align="top" hspace="3">
<span class="heading3">Складність:</span>
</p><ul>
<p>
</p><li>Загалом, паралельні програми набагато складніші, ніж відповідні послідовні програми, можливо, на порядок. Ви не тільки маєте декілька потоків інструкцій, що виконуються одночасно, але також є дані між ними.
<p>
</p></li><li>Вартість складності вимірюється в програміста практично у всіх аспектах циклу розробки програмного забезпечення:
    <ul>
    <li>Дизайн
    </li><li>Кодування
    </li><li>Налагодження
    </li><li>Тюнінг
    </li><li>Технічне обслуговування
    </li></ul>
<p>
</p></li><li>При роботі з паралельними програмами важливо дотримуватися «правильних» правил розробки програмного забезпечення, особливо якщо хтось, крім вас, повинен буде працювати з програмним забезпеченням.
</li></ul>
<p>

<img src="./Introduction to Parallel Computing_files/arrowBullet.gif" align="top" hspace="3">
<span class="heading3">Портативність:</span>
</p><ul>
<p>
</p><li>Завдяки стандартизації в декількох інтерфейсах API, таких як MPI, потоки POSIX та OpenMP, проблеми з переносністю паралельних програм не настільки серйозні, як у минулому. Однак ...
<p>
</p></li><li>Усі звичайні проблеми портативності, пов'язані з серійними програмами, застосовуються до паралельних програм. Наприклад, якщо ви використовуєте "удосконалення" постачальників для Fortran, C або C ++, портативність стане проблемою.
<p>
</p></li><li>Незважаючи на те, що стандарти існують для кількох API, реалізація буде відрізнятися в ряді деталей, іноді до необхідності внесення змін до коду, щоб забезпечити перенесення коду.
<p>
</p></li><li>Операційні системи можуть відігравати ключову роль у питаннях перенесення коду.
<p>
</p></li><li>Апаратні архітектури характеризуються високою мінливістю і можуть вплинути на перенесення коду.
</li></ul>
<p>

<img src="./Introduction to Parallel Computing_files/arrowBullet.gif" align="top" hspace="3">
<span class="heading3">Вимоги до ресурсів:</span>
</p><ul>
<p>
</p><li>Основним наміром паралельного програмування є зменшення часу виконання завдання, однак для цього потрібно більше часу для процесора. Наприклад, паралельний код, який працює протягом 1 години на 8 процесорах, насправді використовує 8 годин процесора.
<p>
</p></li><li>Обсяг необхідної пам'яті може бути більшим для параленього коду, ніж серійний код, у зв'язку з необхідністю реплікації даних та накладних витрат, пов'язаних з паралельними бібліотеками підтримки.
<p>
</p></li><li>Для короткого запуску паралельних програм фактично може бути зниження продуктивності в порівнянні з аналогічною серійною реалізацією. Накладні витрати, пов'язані з налаштуванням паралельного середовища, створення завдання, зв'язку та завершення завдання, можуть скласти значну частину загального часу виконання коротких циклів.
</li></ul>
<p>

<img src="./Introduction to Parallel Computing_files/arrowBullet.gif" align="top" hspace="3">
<span class="heading3">Масштабованість:</span>
</p><ul>
<p>
</p><li>Існують два типи масштабування, кожне залежать від часу: сильне масштабування та слабке масштабування.
<p>

<img src="./Introduction to Parallel Computing_files/strongWeakScaling.gif" align="right" hspace="20" width="300">
</p></li><li><b>Сильне масштабування:</b> 
<ul>
<li>Загальний розмір проблеми залишається фіксованим, оскільки додається більше процесорів.
</li><li>Мета - розвязати один і той же розмір проблеми швидше.
</li><li>Ідеальне масштабування означає, що проблема вирішується в 1 / P час (у порівнянні з серійним).
</li></ul>
<p>
</p></li><li><b>Слабке масштабування:</b> 
<ul>
<li>Розмір задач <i>на одному процесорі</i> залишається фіксованим, оскільки додається більше процесорів.
</li><li>Мета - розвязати більшу проблему в той самий час.
</li><li>Відмінне масштабування означає, що проблема Px запускається в той самий час, що і запуск одного процесора.
</li></ul>
<p>
</p></li><li>Здатність виконання паралельної програми до масштабу є результатом ряду взаємопов'язаних факторів. Просто додавання інших процесорів рідко відповідає вирішенню проблем паралельного програмування.
<p>
</p></li><li>Алгоритм може мати внутрішні межі масштабованості. У якийсь момент додавання додаткових ресурсів призводить до зниження продуктивності. Це загальна ситуація з багатьма паралельними додатками.
<p>
</p></li><li>Апаратні фактори відіграють значну роль у маштабуванні. Приклади:
    <ul>
    <li>Пропускна здатність шини Memory-cpu на машині SMP
    </li><li>Пропускна здатність зв'язку в мережі
    </li><li>Кількість пам'яті, доступної на будь-якій машині чи наборі машин
    </li><li>Тактова частота процесора
    </li></ul>    
<p>
</p></li><li>Програмне забезпечення паралельних бібліотек та підсистем може обмежувати масштабованість, незалежно від вашої програми.
</li></ul>

<!--========================================================================-->

<a name="MemoryArch"> <br><br> </a>
<a name="SharedMemory"> </a>
<table border="1" cellpadding="5" cellspacing="0" width="100%">
<tbody><tr><td bgcolor="#98ABCE">
<span class="heading1">Паралельні архітектури пам'яті комп'ютера</span></td>
</tr></tbody></table>
<h2>Спільна пам'ять</h2>

<img src="./Introduction to Parallel Computing_files/arrowBullet.gif" align="top" hspace="3">
<span class="heading3">Загальна характеристика:</span>
<p>
<table cellpadding="0" cellspacing="0">
<tbody><tr valign="top">
<td><ul>
<li>Паралельні комп'ютери із загальною пам'яттю знаходяться в широкому діапазоні, але загалом мають загальну здатність всіх процесорів отримати доступ до всієї пам'яті як до глобального адресного простору.
<p>
</p></li><li>Кілька процесорів можуть працювати незалежно, але розділяють ті ж ресурси пам'яті.
<p>
</p></li><li>Зміни в пам'яті, здійснені одним процесором, видні для всіх інших процесорів.
<p>
</p></li><li>Історично загальні пристрої пам'яті були класифіковані як
    <b><i>UMA</i></b> та <b><i>NUMA</i></b>,  на основі часу доступу до пам'яті.
<p>
</p></li></ul>
<p>

<img src="./Introduction to Parallel Computing_files/arrowBullet.gif" align="top" hspace="3">
<span class="heading3">Єдиний доступ до пам'яті (UMA):</span>
    </p><ul>
    <li>Найбільш часто представлені сьогодні <b><i>симетричними багатопроцесорними (SMP)</i></b> машинами
    </li><li>Ідентичні процесори
    </li><li>Рівний доступ та час доступу до пам'яті 
    </li><li>Іноді називають CC-UMA - Cache Coherent UMA. Кеш-когерентний означає, якщо один процесор оновлює місцеположення в спільній пам'яті, всі інші процесори знають про оновлення. Когерентність кешів здійснюється на апаратному рівні.
    </li></ul>
<p>

<img src="./Introduction to Parallel Computing_files/arrowBullet.gif" align="top" hspace="3">
<span class="heading3">Неоднорідний доступ до пам'яті (NUMA):</span>
    </p><ul>
    <li>Часто здійснюється шляхом фізичного з'єднання двох або більше SMP 
    </li><li>Один SMP може безпосередньо отримати доступ до пам'яті іншого SMP
    </li><li>Не всі процесори мають рівний час доступу до всієї пам'яті
    </li><li>Доступ до пам'яті через посилання повільний
    </li><li>Якщо підтримується когерентність кеш-пам'яті, то її також можна назвати CC-NUMA - Cache Coherent NUMA

    </li></ul>
<p>
<img src="./Introduction to Parallel Computing_files/arrowBullet.gif" align="top" hspace="3">
<span class="heading3">Переваги:</span>
    </p><ul>
    <li>Глобальний адресний простір забезпечує зручну для користувача програмування пам'ять
    </li><li>Обмін даними між завданнями є швидким та однорідним завдяки близькості пам'яті до процесорів
    </li></ul>
</td>
<td align="center"><img src="./Introduction to Parallel Computing_files/shared_mem.gif" width="414" height="285">
<br><b>Спільна пам'ять (UMA)</b><br><br><br>
<img src="./Introduction to Parallel Computing_files/numa.gif" width="484" height="196">
<br><b>Спільна пам'ять (NUMA)</b>
</td>
</tr></tbody></table>
</p><p>

<img src="./Introduction to Parallel Computing_files/arrowBullet.gif" align="top" hspace="3">
<span class="heading3">Недоліки:</span>
</p><ul>
<li>Primary disadvantage is the lack of scalability between memory and CPUs.
    Adding more CPUs can geometrically increases traffic on the shared
    memory-CPU path, and for cache coherent systems, geometrically increase 
    traffic associated with cache/memory management. 
</li><li>Programmer responsibility for synchronization constructs that ensure
    "correct" access of global memory. 
</li></ul>


<!--========================================================================-->
<p>
<a name="DistributedMemory"> <br><br> </a>
<table border="1" cellpadding="5" cellspacing="0" width="100%">
<tbody><tr><td bgcolor="#98ABCE">
<span class="heading1">Паралельні архітектури пам'яті комп'ютера</span></td>
</tr></tbody></table>
</p><h2>Розподілена пам'ять</h2>

<img src="./Introduction to Parallel Computing_files/arrowBullet.gif" align="top" hspace="3">
<span class="heading3">Загальні характеристики:</span>
<ul>
<p>
</p><li>Як і в системах спільної пам'яті, системи розподіленої пам'яті дуже різні, але мають спільну характеристику. Для розподілених систем пам'яті потрібна мережа зв'язку для підключення міжпроцесорної пам'яті.
<p>
<img src="./Introduction to Parallel Computing_files/distributed_mem.gif" width="484" height="196" hspace="10">
</p><p>
</p></li><li>Процесори мають свою локальну пам'ять. Адреси пам'яті в одному процесорі не відображаються на іншому процесорі, тому немає поняття про глобальний адресний простір у всіх процесорах.
<p>
</p></li><li>Оскільки кожен процесор має свою локальну пам'ять, вона працює самостійно. Зміни, внесені в її локальну пам'ять, не впливають на пам'ять інших процесорів. Отже, поняття когерентності кеш-пам'яті не застосовується.
<p>
</p></li><li>Коли процесору потрібен доступ до даних в іншому процесорі, як правило, це завдання для програміста явно визначити, як і коли дані передаються. Синхронізація завдань також є відповідальністю програміста.
<p>
</p></li><li>Мережа "fabric" (тканина), що використовується для передачі даних, широко відрізняється, хоча це може бути настільки ж просто, як Ethernet.
</li></ul>
<p>

<img src="./Introduction to Parallel Computing_files/arrowBullet.gif" align="top" hspace="3">
<span class="heading3">Переваги:</span>
    </p><ul>
    <li>Пам'ять масштабується з кількістю процесорів. Збільшення кількості процесорів і розмір пам'яті збільшуються пропорційно. 
    </li><li>Кожен процесор може швидко отримати доступ до власної пам'яті без перешкод і без накладних витрат, намагаючись зберегти узгодженість глобальної кеш-пам'яті.
    </li><li>Ефективність витрат: можна використовувати товарний, незалежний процесор та мережу.
    </li></ul>
<p>

<img src="./Introduction to Parallel Computing_files/arrowBullet.gif" align="top" hspace="3">
<span class="heading3">Недоліки:</span>
    </p><ul>
    <li>Програміст несе відповідальність за багато деталей, пов'язаних з передачею даних між процесорами.
    </li><li>Можливо, буде важко структурувати існуючі структури даних на основі глобальної пам'яті для цієї організації пам'яті.
    </li><li>Неоднорідний час доступу до пам'яті - дані, що знаходяться на віддаленому вузлі, мають більший час доступу, ніж локальні дані вузла.
    </li></ul>



<!--========================================================================-->
<p>
<a name="HybridMemory"> <br><br> </a>
<table border="1" cellpadding="5" cellspacing="0" width="100%">
<tbody><tr><td bgcolor="#98ABCE">
<span class="heading1">Паралельні архітектури пам'яті комп'ютера</span></td>
</tr></tbody></table>
</p><h2>Гібридна розподілена загальна пам'ять</h2>

<img src="./Introduction to Parallel Computing_files/arrowBullet.gif" align="top" hspace="3">
<span class="heading3">Загальні характеристики:</span>
<ul>
<p>
</p><li>Найбільші та найшвидкісніші комп'ютери у світі сьогодні використовують як загальні, так і розподілені архітектури пам'яті.
<p>
<table border="0" cellpadding="0" cellspacing="0">
<tbody><tr valign="top">
<td><img src="./Introduction to Parallel Computing_files/hybrid_mem.gif" width="484" height="196" hspace="10"></td>
<td><img src="./Introduction to Parallel Computing_files/hybrid_mem2.gif" width="484" height="196" hspace="10"></td>
</tr></tbody></table>
</p><p>
</p></li><li>Компонентом спільної пам'яті може бути загальна пам'ять та / або графічні модулі (GPU).
<p>
</p></li><li>Компонент розподіленої пам'яті являє собою мережу з декількома машинами іх спільною пам'яттю / графічним процесором, які знають лише про власну пам'ять, а не про пам'ять на іншій машині. Тому мережеві зв'язки необхідні для переміщення даних з однієї машини в іншу.
<p>
</p></li><li>Поточні тенденції, схоже, вказують на те, що такий тип архітектури пам'яті продовжуватиме переважати і збільшуватись на найвищому рівні обчислень у найближчому майбутньому.
</li></ul>
<p>

<img src="./Introduction to Parallel Computing_files/arrowBullet.gif" align="top" hspace="3">
<span class="heading3"> Переваги та недоліки:</span>
</p><ul>
<li>Що б не було загальним як для загальної, так і для розподіленої архітектури пам'яті. 
</li><li>Підвищене маштабування - важлива перевага.
</li><li>Збільшення складності програміста є важливим недоліком.
</li></ul>


<!--========================================================================-->
<p>
<a name="Models"> <br><br> </a>
<a name="ModelsOverview"> </a>
<table border="1" cellpadding="5" cellspacing="0" width="100%">
<tbody><tr><td bgcolor="#98ABCE">
<span class="heading1">Моделі паралельного програмування</span></td>
</tr></tbody></table>
</p><h2>Огляд</h2>

<ul>
<p>
</p><li>Існує кілька моделей паралельного програмування, що використовуються у спільному використанні:
    <ul>
    <li>Спільна пам'ять (без потоків)
    </li><li>Нитки
    </li><li>Розподілена пам'ять / передача повідомлень
    </li><li>Паралельні дані
    </li><li>Гібридний
    </li><li>Один тип даних декількох програм (SPMD)
    </li><li>Декілька видів даних декількох програм (MPMD)
    </li></ul>
<p>
</p></li><li><b>Паралельні моделі програмування існують як абстракція над архітектурою апаратного забезпечення та пам'яті.</b>
<p>
</p></li><li>Хоча це може здатися незрозумілим, ці моделі <b>НЕ</b> специфічні для певного типу архітектури машини або пам'яті. Фактично, будь-яка з цих моделей може (теоретично) бути реалізована на будь-якому базовому апаратному забезпеченні. Два приклади з минулого обговорюються нижче.
<p>
<table border="0" cellspacing="0" cellpadding="0" width="800">
<tbody><tr valign="top">
<td colspan="2">
<b>СПІЛЬНА модель пам'яті на ДИСКОВІЙ пам'яті:</b> 
<br>Kendall Square Research (KSR) ALLCACHE підхід. Машинна пам'ять фізично поширювалася на мережевих машинах, але з'являлася користувачеві як єдиний глобальний адресний простір загальної пам'яті. Як правило, цей підхід називається "віртуальною спільною пам'яттю".
</td></tr><tr valign="top">
<td><img src="./Introduction to Parallel Computing_files/modelAbstraction1.gif" height="150" vspace="20"></td>
<td><img src="./Introduction to Parallel Computing_files/ksr1.gif" width="198" height="130" vspace="20"></td>
</tr><tr valign="top">
<td colspan="2">
<b>Розподілена модель пам'яті на комп'ютері із СПІЛЬНОЇ пам'ятю:</b> 
<br>Інтерфейс передачі повідомлень (MPI) на SGI Origin 2000. SGI Origin 2000 використовував архітектуру спільної пам'яті типу CC-NUMA, де кожне завдання має прямий доступ до глобального адресного простору, що поширюється по всіх машинах. Проте реалізація і широко використовувана можливість надіслати та отримувати повідомлення за допомогою MPI, як правило, здійснюється через мережу розподілених комп'ютерів.
</td></tr><tr valign="top">
<td><img src="./Introduction to Parallel Computing_files/modelAbstraction2.gif" height="150" vspace="20"></td>
<td><img src="./Introduction to Parallel Computing_files/sgiOrigin2000.jpg" width="198" height="149" vspace="20"></td>
</tr></tbody></table>
</p><p>
</p></li><li><b>Яку модель використовувати?</b> 
   Це часто є поєднанням того, що є і особистий вибір. Немає "найкращої" моделі, хоча, звичайно, є кращі реалії деяких моделей над іншими.
<p>
</p></li><li>У наступних розділах описано кожну з моделей, згаданих вище, а також обговорюються деякі їх фактичні реалізації.
</li></ul>


<!--========================================================================-->
<p>
<a name="ModelsShared"> <br><br> </a>
<table border="1" cellpadding="5" cellspacing="0" width="100%">
<tbody><tr><td bgcolor="#98ABCE">
<span class="heading1">Моделі паралельного програмування</span></td>
</tr></tbody></table>
</p><h2>Модель спільної пам'яті (без потоків)</h2>

<ul>
<img src="./Introduction to Parallel Computing_files/sharedMemoryModel.gif" width="350" hspace="20" align="right">
<li>У цій моделі програмування процеси / завдання поділяють на загальний адресний простір, в який вони читають та записують асинхронно.
<p>
</p></li><li>Різні механізми, такі як замки / семафори, використовуються для контролю доступу до спільної пам'яті, вирішення спорів та запобігання перегонах з пам'яттю та тупиковим умовам.
<p>
</p></li><li>Це, мабуть, найпростіша модель паралельного програмування.
<p>
</p></li><li>Перевага цієї моделі з точки зору програміста полягає в тому, що поняття "власність" даних не вистачає, тому немає потреби явно вказати обмін даними між завданнями. Всі процеси бачать і мають рівний доступ до спільної пам'яті. Завдяки цьому, розробку програми часто можна спростити.
<p>
</p></li><li>Важливим недоліком з точки зору продуктивності є те, що стає все важче зрозуміти та керувати <b><i>локацією даних</i></b>:
    <ul>
    <li>Ведення локальних даних у процесі, який працює з ними, зберігає доступ до пам'яті, оновлення кеша та трафік, який виникає, коли декілька процесів використовують однакові дані.
    </li><li>На жаль, керування локальними даними важко зрозуміти і може перебувати під контролем середнього користувача.
    </li></ul>
</li></ul>
<p>

<img src="./Introduction to Parallel Computing_files/arrowBullet.gif" align="top" hspace="3">
<span class="heading3">Реалізації:</span>
</p><ul>
    <p>
    </p><li>На автономних машинах спільної пам'яті, нативна операційна система, компілятори та / або апаратні засоби забезпечують підтримку програмування спільної пам'яті. Наприклад, стандарт POSIX забезпечує API для використання спільної пам'яті, а UNIX забезпечує спільні сегменти пам'яті (shmget, shmat, shmctl тощо).
    <p>
    </p></li><li>На розподілених машинах пам'яті фізично розподіляється пам'ять через мережу машин, але робиться глобальною за допомогою спеціалізованого апаратного та програмного забезпечення. Доступні різні реалізації SHMEM:
        <a href="http://en.wikipedia.org/wiki/SHMEM" target="_blank">
        http://en.wikipedia.org/wiki/SHMEM</a>.
    </li></ul>


<!--========================================================================-->
<p>
<a name="ModelsThreads"> <br><br> </a>
<table border="1" cellpadding="5" cellspacing="0" width="100%">
<tbody><tr><td bgcolor="#98ABCE">
<span class="heading1">Моделі паралельного програмування</span></td>
</tr></tbody></table>
</p><h2>Моделі ниток</h2>

<ul>
<p>
</p><li>Ця модель програмування є типом спільного програмного забезпечення пам'яті.
</p></li><li>У поточній моделі паралельного програмування, один "важкий" процес може мати кілька "легких", одночасних шляхів виконання.
<p>
</p></li><li>Наприклад:

<img src="./Introduction to Parallel Computing_files/threadsModel2.gif" align="right" width="350" height="550" hspace="20">
    <ul>
    <p>
    </p><li>Основна програма <b>a.out</b> планується бути запущена в нативну операційну систему <b>a.out</b> авантажує та отримує всі необхідні системні та користувацькі ресурси для запуску. Це "важка вага" процесу.
    <p>
    </p></li><li><b>a.out</b> виконує деяку послідовну роботу, а потім створює ряд завдань (потоків), які можуть бути заплановані та запущені операційною системою одночасно.
    <p>
    </p></li><li>Кожна нитка має локальні дані, але також ділиться всіма ресурсами
        <b>a.out</b>. Це заощаджує накладні витрати, пов'язані з тиражуванням ресурсів програми для кожного потоку ("легка вага"). Кожна нитка також користується глобальною пам'яттю, оскільки вона поділяє простір пам'яті  <b>a.out</b>.      
    <p>
    </p></li><li>Роботу нитки найкраще можна описати як підпрограму в рамках основної програми. Будь-який поток може виконувати будь-яку підпрограму одночасно з іншими потоками.
    <p>
    </p></li><li>Нитки взаємодіють між собою через глобальну пам'ять (оновлення адреси). Для цього потрібні конфігурації синхронізації, щоб переконатися, що більше ніж одне поточне оновлення не підтримує ту ж глобальну адресу.
    <p>
    </p></li><li>Нитки можуть прийти і йти, але <b>a.out</b> залишається присутнім, щоб забезпечити необхідні спільні ресурси до закінчення програми.
    </li></ul>
    <p>
</p></li></ul>
<p>

<img src="./Introduction to Parallel Computing_files/arrowBullet.gif" align="top" hspace="3">
<span class="heading3">Реалізації:</span>
</p><ul>
<li>З точки зору програмування, реалізація потоків зазвичай включає:
    <ul type="circle">
    <li>Бібліотека підпрограм, яка викликається з паралельного вихідного коду
    </li><li>Набір директив компіляторів, вбудований як в серійний, так і в паралельний вихідний код
    </li></ul>
<p>
    В обох випадках програміст несе відповідальність за визначення паралелізму (хоча компілятори іноді можуть допомогти).
</p><p>
</p></li><li>Реалізації ниток не є новими в обчисленні. Історично постачальники обладнання реалізували власні версії потоків. Ці реалізації істотно відрізнялися один від одного, що ускладнює програмістам розробляти портативні програми.
<p>
</p></li><li>Незв'язані зусилля зі стандартизації привели до двох дуже різних реалізацій ниток:
    <b><i>POSIX Threads</i></b> та <b><i>OpenMP</i></b>.
<p>
</p></li><li><b>POSIX нитки</b> 
    <ul>
    <li>Зазначений стандартом IEEE POSIX 1003.1c (1995). C тільки мова.
    </li><li>Частина операційних систем Unix / Linux.
    </li><li>Бібліотека на базі.
    </li><li>Зазвичай називають Pthreads.
    </li><li>Дуже явний паралелізм; вимагає значної уваги програміста до деталей.
    </li></ul>
<p>
</p></li><li><b>OpenMP</b>  
    <ul>
    <li>Промисловий стандарт, спільно визначений і схвалений групою основних постачальників комп'ютерних апаратних і програмних продуктів, організацій та окремих осіб.
    </li><li>Директор компіляції заснований
    </li><li>Портативний / багатоплатформнний, включаючи платформи Unix і Windows
    </li><li>Доступно в реалізаціях C / C ++ та Fortran
    </li><li>Може бути дуже простим у використанні - забезпечує "додатковий паралелізм". Можна починати з серійного коду.
    </li></ul>
<p>
</p></li><li>Інші поточні реалізації є загальними, але тут не обговорюються:
<ul>
<li>Нитки Microsoft
</li><li>Java, Python нитки
</li><li>CUDA нитки для графічних процесорів
</li></ul>

</li></ul>
<p>

<img src="./Introduction to Parallel Computing_files/arrowBullet.gif" align="top" hspace="3">
<span class="heading3">Більше інформації:</span>
</p><ul>
<li>POSIX Threads уроки: 
<a href="https://computing.llnl.gov/tutorials/pthreads/" target="pthreads">
computing.llnl.gov/tutorials/pthreads</a>
</li><li>OpenMP уроки: 
<a href="https://computing.llnl.gov/tutorials/openMP/" target="openMP">
computing.llnl.gov/tutorials/openMP</a>
</li></ul>

<!--========================================================================-->

<a name="ModelsMessage"> <br><br> </a>
<table border="1" cellpadding="5" cellspacing="0" width="100%">
<tbody><tr><td bgcolor="#98ABCE">
<span class="heading1">Моделі паралельного програмування</span></td>
</tr></tbody></table>
<h2>Розподілена пам'ять / Модель обмін повідомленнями</h2>

<ul>
<p>
</p><li>Ця модель демонструє наступні характеристики:
<img src="./Introduction to Parallel Computing_files/msg_pass_model.gif" align="right" width="446" height="310" hspace="10" vspace="10">
    <ul>
    <p>
    </p><li>Набір завдань, які використовують власну 
    	локальну пам'ять під час обчислень. Кілька 
    	завдань можуть знаходитись на тій же фізичній
    	машині та / або на довільній кількості машин.
    <p>
    </p></li><li>Завдання обмінюються даними через 
    	повідомлення, відправляючи та отримуючи 
    	повідомлення.
    <p>
    </p></li><liПередача даних зазвичай вимагає кооперативних
    	операцій для кожного процесу. Наприклад, 
    	операція відправки повинна мати відповідну 
    	операцію прийому.
    </li></ul> 
</li></ul>
<p>

<img src="./Introduction to Parallel Computing_files/arrowBullet.gif" align="top" hspace="3">
<span class="heading3">Реалізації:</span>
</p><ul>
<li>З точки зору програмування, реалізація передачі 
	повідомлень зазвичай складається з бібліотеки підпрограм. Виклики на ці підпрограми вкладені в вихідний код. Програміст несе відповідальність за визначення всіх паралелізму.
<p>
</p></li><li>Історично склалося, що з 80-х років доступні різні бібліотеки повідомлень. Ці реалізації суттєво 	відрізнялися один від одного, що ускладнює програмістам розробляти портативні програми. 
<p>
</p></li><li>У 1992 році був створений Форум MPI з основною метою створення стандартного інтерфейсу для 		реалізації послань до повідомлень. 
<p>
</p></li><li>Частина 1 <b>Message Passing Interface (MPI)</b> була випущена в 1994 році. Частина 2 
	(MPI-2) була випущена в 1996 році і MPI-3 в 2012 році. Всі специфікації MPI доступні в Інтернеті за адресою
    <a href="http://www.mpi-forum.org/docs/" target="_blank">http://www.mpi-forum.org/docs/</a>.
<p>
</p></li><li>MPI - це "фактичний" галузевий стандарт для передачі повідомлень, який замінює практично всі 		інші реалізовані повідомлення, що використовуються для виробничої роботи. Реалізації MPI існують 			практично для всіх популярних паралельних обчислювальних платформ. Не всі реалізації включають все в 		MPI-1, MPI-2 або MPI-3.
</li></ul>
<p>

<img src="./Introduction to Parallel Computing_files/arrowBullet.gif" align="top" hspace="3">
<span class="heading3">Більше інформації:</span>
</p><ul>
<li>Підручник з MPI: 
<a href="https://computing.llnl.gov/tutorials/mpi/" target="mpi">
computing.llnl.gov/tutorials/mpi</a>
</li></ul>

<!--========================================================================-->

<a name="ModelsData"> <br><br> </a>
<table border="1" cellpadding="5" cellspacing="0" width="100%">
<tbody><tr><td bgcolor="#98ABCE">
<span class="heading1">Моделі паралельного програмування</span></td>
</tr></tbody></table>
<h2>Паралельна модель даних</h2>

<ul>
<p>
</p><li>Може також називатися <b>Partitioned Global Address Space (PGAS)</b>.
<p>
</p></li><li>Дана паралельна модель демонструє такі характеристики: 

<img src="./Introduction to Parallel Computing_files/data_parallel_model.gif" align="right" width="409" height="362" hspace="10" vspace="10">
    <ul>
    <p>
    </p><li>Адресний простір розглядається глобально
    <p>
    </p></li><li>Велика частина паралельної роботи зосереджена на виконанні операцій на 
    	наборі даних. Набір даних, як правило, організований у 
    	загальну структуру, таку як масив або куб.
    <p>
    </p></li><li>Набір завдань спільно працює на тій же структурі 
    	даних, однак кожне завдання працює на іншому розділі тієї ж структури даних.
    <p>
    </p></li><li>Завдання виконують одну й ту саму операцію при їх розподілі роботи, 
    	наприклад, "додати 4 до кожного елементу масиву".
    </li></ul>
<p>
</p></li><li>На загальних архітектурах пам'яті всі завдання можуть мати 
	доступ до структури даних через глобальну пам'ять.
<p>
</p></li><li>У розподілених архітектурах пам'яті глобальна структура 
	даних може бути логічно та / або фізично розподілена між завданнями.
</li></ul>
<br clear="">
<p>

<img src="./Introduction to Parallel Computing_files/arrowBullet.gif" align="top" hspace="3">
<span class="heading3"> Реалізації:</span>
</p><ul>
<p>
</p><li>В даний час існує декілька відносно популярних, а інколи і розроблювальних, 
	паралельних програмних рішень на основі моделі Data Parallel / PGAS.
<p>
</p></li><li><b>Coarray Fortran:</b> невеликий набір розширень для Fortran 95 для парамного програмування		 SPMD. Компілятор залежить. Додаткова інформація: 
    <a href="https://en.wikipedia.org/wiki/Coarray_Fortran" target="_blank">https://en.wikipedia.org/wiki/Coarray_Fortran</a>
<p>
</p></li><li><b>Unified Parallel C (UPC):</b> розширення на мову програмування C для паралельного 				програмування SPMD. Компілятор залежить. Додаткова інформація: 
    <a href="http://upc.lbl.gov/" target="_blank">http://upc.lbl.gov/</a>
<p>
</p></li><li><b>Global Arrays:</b> забезпечує спільне середовище програмування стилю пам'яті в контексті структури даних розподіленого масиву. Бібліотека публічного домену із закріпленнями C і Fortran77. Додаткова інформація:
    <a href="https://en.wikipedia.org/wiki/Global_Arrays" target="_blank">
    https://en.wikipedia.org/wiki/Global_Arrays</a>
<p>
</p></li><li><b>X10:</b> мова паралельного програмування на базі PGAS, розроблена компанією IBM в дослідницькому центрі ім. Томаса Дж. Уотсона. Більш детальна інформація:
    <a href="http://x10-lang.org/" target="_blank">http://x10-lang.org/</a>
<p>
</p></li><li><b>Chapel:</b> проект з паралельним програмуванням з відкритим кодом під керівництвом Cray. Додаткова інформація: 
    <a href="http://chapel.cray.com/" target="_blank">http://chapel.cray.com/</a>
</li></ul>

<!--========================================================================-->

<a name="Hybrid"> <br><br> </a>
<table border="1" cellpadding="5" cellspacing="0" width="100%">
<tbody><tr><td bgcolor="#98ABCE">
<span class="heading1">Моделі паралельного програмування</span></td>
</tr></tbody></table>
<h2>Гібридна модель</h2>

<table border="0" cellspacing="0" cellpadding="0">
<tbody><tr valign="top">
<td>
<ul>
<li>Гібридна модель поєднує в собі більше ніж одну з описаних раніше моделей програмування.
<p>
</p></li><li>В даний час загальним прикладом гібридної моделі є поєднання моделі 
	передачі повідомлень (MPI) з моделлю потоків (OpenMP).
    <ul>
    <li>Потоки виконують інтенсивні обчислювальння ядра, використовуючи локальні,
        дані на вузлі
    </li><li>Зв'язок між процесами на різних вузлах відбувається по мережі за допомогою MPI
    </li></ul> 
<p>
</p></li><li>Ця гібридна модель добре поширюється на найпопулярнішу (в даний час) апаратне середовище кластеризованих мульти / багатоядерних машин. 
<p>
</p></li><li>Іншим подібним і все більш популярним прикладом гібридної моделі є використання MPI з процесором-графічним процесором (Graphics Processing Unit - програма обробки графіки).
    <ul>
    <li>Завдання MPI працюють на процесорах із використанням локальної пам'яті та спілкування між собою через мережу.
    </li><li>Обчислювальні інтенсивні ядра вивантажуються на вузли графічних процесорів.
    </li><li>Обмін даними між вузлом-локальною пам'яттю та графічними процесорами використовує CUDA (або щось еквівалентне).
    </li></ul>
<p>
</p></li><li>Інші гібридні моделі є загальними:
    <ul>
    <li>MPI with Pthreads
    </li><li>MPI з не-GPU прискорювачами
    </li><li>...
    </li></ul>
</li></ul>
</td>
<td align="right">
<img src="./Introduction to Parallel Computing_files/hybrid_model.gif" width="485" height="241" hspace="20">
<br>
<img src="./Introduction to Parallel Computing_files/hybrid_model2.gif" width="485" height="209" hspace="20" vspace="20">
</td></tr></tbody></table>


<!--========================================================================-->

<a name="SPMD-MPMD"> <br><br> </a>
<table border="1" cellpadding="5" cellspacing="0" width="100%">
<tbody><tr><td bgcolor="#98ABCE">
<span class="heading1">Моделі паралельного програмування</span></td>
</tr></tbody></table>
<h2>SPMD and MPMD</h2>

<img src="./Introduction to Parallel Computing_files/arrowBullet.gif" align="top" hspace="3">
<span class="heading3">Одноразові дані декількох програм (SPMD):</span>
<ul>
<p>
</p><li>SPMD - це насправді модель програмування "високого рівня", яка може бути побудована на будь-якій комбінації раніше згаданих моделей паралельного програмування.
<img src="./Introduction to Parallel Computing_files/spmd_model.gif" align="right" width="395" height="110" hspace="10" vspace="10">

<p>
</p></li><li>SINGLE PROGRAM:  всі завдання виконують свою копію однієї і тієї ж програми одночасно. Ця програма може бути потоками, передаванням повідомлень, паралельними або гібридними даними.
<p>
</p></li><li>MULTIPLE DATA: Всі завдання можуть використовувати різні дані
<p>
</p></li><li>Програми SPMD зазвичай мають необхідну логіку, запрограмовану в них, щоб дозволити різним завданням відгалужуватися або умовно виконувати лише ті частини програми, які вони призначені для виконання. Тобто завдання не обов'язково повинні виконувати всю програму - можливо, лише її частину.
<p>
</p></li><li>Модель SPMD, що використовує передавання повідомлень або гібридне програмування, є, 	мабуть, найбільш часто використовуваною моделлю паралельного програмування для багатонасельних 	кластерів.
</li></ul>
<p>

<img src="./Introduction to Parallel Computing_files/arrowBullet.gif" align="top" hspace="3">
<span class="heading3">Кілька даних декількох програм (MPMD):</span>
</p><ul>
<p>
</p><li>Як і SPMD, MPMD насправді є моделлю програмування "високого рівня", яка може бути 			побудована на будь-якій комбінації раніше згаданих моделей паралельного програмування.

<img src="./Introduction to Parallel Computing_files/mpmd_model.gif" align="right" width="395" height="110" hspace="10" vspace="10">

<p>
</p></li><li>MULTIPLE PROGRAM: Завдання можуть виконувати різні програми одночасно. Програмами можуть бути потоки, передача повідомлень, дані паралельні або гібридні.
<p>
</p></li><li>MULTIPLE DATA: Всі завдання можуть використовувати різні дані
<p>
</p></li><li>MPMD-програми не настільки поширені, як програми SPMD, але можуть бути краще підходять для певних типів проблем, особливо тих, які краще піддаються функціональному розкладу, ніж розбиттям домену (обговорене пізніше під розділом <a href="https://computing.llnl.gov/tutorials/parallel_comp/#DesignPartitioning">
    Partioning</a>).
</li></ul>

<!--========================================================================-->
<p>
<a name="Designing"> <br><br> </a>
<a name="DesignAutomatic"> </a>
<table border="1" cellpadding="5" cellspacing="0" width="100%">
<tbody><tr><td bgcolor="#98ABCE">
<span class="heading1">Розробка паралельних програм</span></td>
</tr></tbody></table>
</p><h2Автоматична або ручна паралелізація </h2>

<ul>
<p>
</p><li>Проектування та розробка паралельних програм характерно було дуже ручним процесом. Програміст, як правило, несе відповідальність за ідентифікацію та фактичне здійснення паралелізму.
<p>
</p></li><li>Дуже часто ручні розробки паралельних кодів - це багато часу, складний, схильний до помилок та <i><b>ітераційний</b></i> процес.
<p>
</p></li><li>Протягом кількох років існують різні інструменти, які допомагають програмісту перетворити серійні програми на паралельні програми. Найпоширеніший тип інструмента, який використовується для автоматичного розпаралелювання серійної програми, - це компілятор, що розпаралелює, або попередній процесор.
<p>
</p></li><li>Компонент, що розпаралелює, зазвичай працює двома способами:
<p>
<b>Повністю автоматичний</b>
</p><ul>
<li>Компілятор аналізує вихідний код та визначає можливості паралелізму.  
</li><li>Аналіз включає в себе ідентифікацію інгібіторів паралелізму та, можливо, розрахунок витрат на те, чи паралелізм дійсно покращить продуктивність.
</li><li>Цикли (do, for) - найчастіша мета для автоматичної розпаралелювання.
</li></ul>
<p>
<b>Вручну</b>
</p><ul>
<li>Використовуючи "директиви компілятора" або, можливо, прапори компілятора, програміст явним чином повідомляє компілятору, як паралелізувати код.
</li><li>Може бути в змозі використовувати разом з деякою мірою автоматичної розпаралелювання також.
</li></ul>
<p>
</p></li><li>Найпоширеніша паралілізація, сформована компілятором, виконується за допомогою спільної пам'яті на вузлі та потоків (наприклад, OpenMP).
<p>
</p></li><li>Якщо ви починаєте з існуючого серійного коду та маєте обмеження часу або бюджету, то відповідь може стати автоматичним розпаралелюванням. Проте існує кілька важливих застережень, які застосовуються до автоматичної розпаралелювання:
    <ul>
    <li>Неправильні результати можуть бути отримані
    </li><li>Продуктивність може деградувати
    </li><li>Набагато менш гнучкий, ніж ручне розпаралелювання
    </li><li>Обмежено до підмножини (в основному петель) коду
    </li><li>Може фактично не розпаралелювати код, якщо аналіз компілятора передбачає наявність інгібіторів або код занадто складний
    </li></ul><p>
</p></li><li>Решта цього розділу стосується ручного методу розробки паралельних кодів.
</li></ul>


<!--========================================================================-->
<p>
<a name="DesignUnderstand"> <br><br> </a>
<table border="1" cellpadding="5" cellspacing="0" width="100%">
<tbody><tr><td bgcolor="#98ABCE">
<span class="heading1">Розробка паралельних програм</span></td>
</tr></tbody></table>
</p><h2>Зрозумійте проблему та програму</h2>

<ul>
<p>
</p><li>Безумовно, першим кроком у розробці паралельного програмного забезпечення є спочатку зрозуміти проблему, яку ви хочете вирішити паралельно. Якщо ви починаєте з серійної програми, це вимагає розуміння існуючого коду.
 
<p>
</p></li><li>Перш ніж витрачати час на спробу розробити паралельне рішення задачі, визначте, чи є така проблема дійсно паралізованою. 
<ul>
<p>
</p><li>Приклад простої для розпаралелювання проблеми:
<p>
<table border="1" cellpadding="5" cellspacing="0" width="75%">
<tbody><tr><td><b>
    Обчислити потенційну енергію для кожної з декількох тисяч незалежних конформацій молекули. Коли закінчите, знайдіть мінімальну конформацію енергії.
</b></td></tr></tbody></table>
</p><p>
    Цю проблему можна вирішити паралельно. Кожна молекулярна конформація самостійно визначається. Розрахунок мінімальної конформації енергії також є паралізованою проблемою.
</p><p>
</p></li><li>Приклад проблеми з незмінним паралелізмом: 
<p>
<table border="1" cellpadding="5" cellspacing="0" width="75%">
<tbody><tr><td><b>
    Розрахунок серії Фібоначчі (0,1,1,2,3,5,8,13,21, ...) за допомогою формули:
</b><p><b>F(n) = F(n-1) + F(n-2)
</b><br>
</p></td></tr></tbody></table>
</p><p> Розрахунок значення F (n) використовує такі значення як F (n-1), так і F (n-2), які необхідно спочатку обчислити.  
</p></li></ul> 
</li></ul>
<p>

<table border="0" cellpadding="0" cellspacing="0">
<tbody><tr valign="top">
<td>
<ul>
<li>Визначте  
    <font style="background-color: yellow"><i><b>точки доступу</b></i></font>програми :
    <ul>
    <li>Знайте, де виконується більша частина справжньої роботи. Більшість науково-технічних програм зазвичай виконують більшість своїх робіт у кількох місцях. 
    </li><li>Засоби профілювання та інструменти аналізу продуктивності можуть допомогти тут
    </li><li>Зосередьтеся на розпаралелювання точок доступу та ігноруйте ті розділи програми, що призводить до невеликого використання процесора. 
    </li></ul>
<p>
</p></li><li>Визначте <font style="background-color: yellow"><i><b>вузькі місця</b></i></font>
    в програмі:
    <ul>
    <li>Чи існують ділянки, які непропорційно сповільнюють роботу або призводять до призупинення 	чи відкладені роботи, що паралелізуються? Наприклад, введення / виведення - це, як 			правило, щось, що сповільнює роботу програми.
    </li><li>Може бути можливо перебудувати програму або використовувати інший алгоритм для зменшення або усунення непотрібних повільних областей
    </li></ul>
<p>
</p></li><li>Визначте інгібітори паралелізму. Одним із загальних класів інгібіторів є
    is <i>залежність даних</i>, про що свідчить послідовність Фібоначчі вище.  
<p>
</p></li><li>Вивчіть інші алгоритми, якщо це можливо. Це може бути найважливішим аспектом при розробці паралельної програми.
<p>
</p></li><li>Скористайтеся перевагами оптимізованого паралельного програмного забезпечення сторонніх розробників та високо оптимізованих математичних бібліотек, доступних провідними постачальниками (ESSL IBM, MKL Intel, AMCL AMD та ін.).
</li></ul></td>
<td><img src="./Introduction to Parallel Computing_files/hotspotBottleneck2.jpg" hspace="20"></td>
</tr></tbody></table>


<!--========================================================================-->

<a name="DesignPartitioning"> <br><br> </a>
<table border="1" cellpadding="5" cellspacing="0" width="100%">
<tbody><tr><td bgcolor="#98ABCE">
<span class="heading1">Розробка паралельних програм</span></td>
</tr></tbody></table>
</p><h2>Розбиття</h2>

<ul>
<p>
</p><li>Одним з перших кроків при проектуванні паралельної програми є розбиття цієї проблеми на дискретні "шматки" роботи, які можуть бути розподілені на декілька завдань. Це відоме як розкладання або розбиття.
<p>
</p></li><li>Існує два основних способи розподілу обчислювальної роботи серед паралельних завдань: <b><i>розбиття на ділянки</i></b> і 
    <b><i>функціональне розбиття</i></b>. 
</li></ul>
<p>

<img src="./Introduction to Parallel Computing_files/arrowBullet.gif" align="top" hspace="3">
<span class="heading3">Розподіл ділянок:</span>
    </p><ul>
    <p>
    </p><li>У цьому типі розбиття дані, пов'язані з проблемою, розкладені. Кожна паралельна задача потім працює на частині даних.
    <p><img src="./Introduction to Parallel Computing_files/domain_decomp.gif" width="388" height="216">
    </p><p>
<a name="distributions"> </a>
    </p></li><li>Існують різні способи розподілу даних:
    <p><img src="./Introduction to Parallel Computing_files/distributions.gif" width="502" height="386">
    </p></li></ul>
<p>

<img src="./Introduction to Parallel Computing_files/arrowBullet.gif" align="top" hspace="3">
<span class="heading3">Функціональне розкладання:</span>
    </p><ul>
    <p>
    </p><li>У цьому підході основна увага приділяється виконанню обчислень, а не даним, яким керується обчислення. Проблема розкладається відповідно до роботи, яка повинна бути виконана. Потім кожне завдання виконує частину загальної роботи.
    <p><img src="./Introduction to Parallel Computing_files/functional_decomp.gif" width="587" height="353">
    </p><p>
    </p></li><li>Функціональна декомпозиція добре підходить до проблем, які можна розділити на різні завдання. Наприклад:
        <dl>
        <p>
        </p><dt><b>Моделювання екосистем</b>
        <br>Кожна програма розраховує кількість населення певної групи, де ріст кожної групи залежить від кількості його сусідів. З розвитком часу кожен процес обчислює його поточний стан, потім обмінюється інформацією з сусідніми групами. Всі завдання виконуються, щоб обчислити стан на наступному кроці.
        <p>
        <img src="./Introduction to Parallel Computing_files/functional_ex1.gif" width="567" height="221">
        </p><p>
        </p></dt><dt><b>Обробка</b>
        <br>Набір даних аудіосигналу проходить через чотири різні обчислювальні фільтри. Кожен фільтр є окремим процесом. Перший сегмент даних повинен пройти через перший фільтр, перш ніж перейти до другого. Коли це відбувається, другий сегмент даних проходить через перший фільтр. На той час, коли четвертий сегмент даних знаходиться в першому фільтрі, всі чотири завдання є зайняті.
        <p>
        <img src="./Introduction to Parallel Computing_files/functional_ex2.gif" width="703" height="272">
        </p><p>
        </p></dt><dt><b>Кліматичне моделювання</b>
        <br>Кожна модель може розглядатися як окреме завдання. Стрілки являють собою обмін даними між компонентами під час обчислень: модель атмосфери формує дані швидкості вітру, які використовуються океанською моделлю, модель океану дає дані про температуру поверхні моря, які використовуються моделлю атмосфери тощо.
        <p>
        <table border="0" cellpadding="0" cellspacing="0">
        <tbody><tr valign="top">
        <td><img src="./Introduction to Parallel Computing_files/functional_ex3.gif" width="372" height="257"></td>
        <td><a href="./Introduction to Parallel Computing_files/climateModelling.png" target="_blank">
            <img src="./Introduction to Parallel Computing_files/climateModelling.png" height="257" hspace="50"></a></td>
        </tr></tbody></table>
        </p></dt></dl>
<p>
</p></li><li>Поєднання цих двох типів розкладання задач є загальним і природним.
<p>
</p></li></ul>

<!--========================================================================-->

<a name="DesignCommunications"> <br><br> </a>
<table border="1" cellpadding="5" cellspacing="0" width="100%">
<tbody><tr><td bgcolor="#98ABCE">
<span class="heading1">Розробка паралельних програм</span></td>
</tr></tbody></table>
<h2>Зв'язок</h2>

<img src="./Introduction to Parallel Computing_files/arrowBullet.gif" align="top" hspace="3">
<span class="heading3">Кому потрібні комунікації?</span>
<ul>
<p>Необхідність зв'язку між завданнями залежить від вашої проблеми:
</p><p>
<table border="0" cellspacing="0" cellpadding="0" width="90%">
<tbody><tr valign="top">
<td><b>Вам не потрібні комунікації:</b>
<ul>
<li>Деякі типи проблем можуть бути розкладені та виконані паралельно з практично відсутністю необхідності у спільних даних для передачі даних. Ці типи проблем часто називаються <b><i>незрозуміло паралельними</i></b> - повідомлення або відсутність повідомлень потрібні. 
</li><li>Наприклад, уявіть собі операцію обробки зображення, коли кожен піксель у чорно-білому 		малюнку повинен мати свій колір навпаки. Дані зображення можна легко розподілити на декілька 	 завдань, які потім діють незалежно один від одного, щоб виконувати свою частину роботи.  
</li></ul></td>
<td><b>Вам потрібні комунікації:</b>
<ul>
<li>Більшість паралельних програм не зовсім настільки прості, і вони вимагають завдань для обміну даними один з одним.  
</li><li>Наприклад, проблема з дифузією 2D вимагає задачі знати температури, розраховані завдань, які мають сусідні дані. Зміни сусідніх даних безпосередньо впливають на дані цього завдання.
</li></ul></td>
</tr><tr valign="top">
<td align="center"><br><img src="./Introduction to Parallel Computing_files/black2white.gif"></td>
<td align="center"><br><img src="./Introduction to Parallel Computing_files/heat_partitioned.gif"></td>
</tr></tbody></table>
</p></ul>
<p>

<img src="./Introduction to Parallel Computing_files/arrowBullet.gif" align="top" hspace="3">
<span class="heading3">Фактори, які слід враховувати:</span>
</p><ul>
<p>
При розробці міжзадачних комунікацій вашої програми необхідно враховувати ряд важливих факторів:
</p><p>
<img src="./Introduction to Parallel Computing_files/commOverhead.jpg" align="right" hspace="20" width="250">
</p><li><b>Комунікаційні накладні витрати</b>
    <ul>
    <li>Міжзазначне спілкування практично завжди означає накладні витрати.
    </li><li>Циклі та ресурси машини, які можуть використовуватися для обчислень, замість цього використовуються для пакетування та передачі даних.
    </li><li>Зв'язок часто вимагає певного типу синхронізації між завданнями, що може призвести до того, що завдання виконуються часом "очікування", а не робота.
    </li><li>Конкуруючий трафік зв'язку може наситити доступну смугу пропускання мережі, що ще більше погіршує проблеми з продуктивністю.
    </li></ul>
<p>
</p></li><li><b>Затримка проти пропускної здатності</b>
    <ul>
    <li><b><i>Затримка</i></b>- це час, який потрібно для відправки мінімального (0 байт) повідомлення з точки А в пункт B. Загально виражений як мікросекунди.
    </li><li><b><i>пропускна здатність</i></b>- це кількість даних, які можна передавати за одиницю часу. Зазвичай виражається як мегабайт / с або гігабайт / с.
    </li><li>Відправка багатьох невеликих повідомлень може призвести до затримки домінування накладних витрат на зв'язок. Часто ефективніше пакуйте невеликі повідомлення у великі повідомлення, тим самим збільшуючи ефективну пропускну здатність зв'язку.
    </li></ul>
<p>
</p></li><li><b>Видимість комунікацій</b>
    <ul>
    <li>З моделлю передачі повідомлень зв'язок є явним і загалом цілком видимим і під контролем програміста. 
    </li><li>За допомогою паралельної моделі даних, комунікації часто прозорі у програмному забезпеченні, особливо в розподілених архітектурах пам'яті. Програміст може навіть не вміти точно знати, як відбувається взаємодія між повідомленнями.
    </li></ul>
<p>
</p></li><li><b>Синхронні або асинхронні комунікації</b>
    <ul>
    <li>Синхронні комунікації вимагають певного типу "рукостискання" між завданнями, які використовують дані. Програміст може чітко структуруватися в коді, або це може статися на більш низькому рівні, невідомий програмісту.
    </li><li>Синхронні комунікації часто називають
        <b><i>блокування</i></b> комунікацій, оскільки інша робота повинна зачекати до завершення зв'язку.
    </li><li>Асинхронні зв'язки дозволяють завданням передавати дані незалежно один від одного. Наприклад, завдання 1 може підготувати і відправити повідомлення до завдання 2, а потім негайно почати робити іншу роботу. Коли завдання 2 фактично отримує дані, це не має значення. 
    </li><li>Асинхронні комунікації часто називають
        <b><i>неблокуючими</i></b> комунікаціями, оскільки інша робота може виконуватися під час спілкування.
    </li><li>Обчислення між класами при спілкуванні є єдиною найбільшою перевагою для використання асинхронних повідомлень.
    </li></ul>
<p>
</p></li><li><b>Обсяг комунікацій</b>
    <ul>
    <li>Знання, які завдання повинні взаємодіяти один з одним, є критичним під час розробки паралельного коду. Обидва описані нижче обчислення можуть бути реалізовані синхронно або асинхронно.
    </li><li><b><i>Point-to-point</i></b> - включає в себе два завдання з одним завданням, що виступає як відправник / виробник даних, а інший - як одержувач / споживач.
        the receiver/consumer.
    </li><li><b><i>Collective</i></b> - включає обмін даними між більш ніж двома завданнями, які часто вказуються як члени спільної групи чи колективу. Деякі загальні варіанти (їх більше):
    <p>
    <img src="./Introduction to Parallel Computing_files/collective_comm.gif"> 
    </p></li></ul>
<p>
</p></li><li><b>Ефективність комунікацій</b>
    <ul>
    <li>Часто, програміст має вибір, який може вплинути на продуктивність зв'язку. Тут згадуються лише деякі.        
    </li><li>Яка реалізація для даної моделі повинна бути використана? Як приклад, як приклад, Модель передачі повідомлень, одна реалізація MPI може бути швидшою на даній апаратній платформі, ніж інша.
    </li><li>Який тип комунікаційних операцій слід використовувати? Як згадувалося раніше, асинхронні операції зв'язку можуть поліпшити загальну продуктивність програми.
    </li><li>Мережева тканина - деякі платформи можуть пропонувати більше однієї мережі для зв'язку. Який з них найкращий?
    </li></ul>
<p>
</p><p>
</p></li><li><b>Накладні та складні</b>
<p>    
    <img src="./Introduction to Parallel Computing_files/helloWorldParallelCallgraph.gif" width="914" height="497">
</p><p>
</p></li><li>Нарешті, зрозумійте, що це лише частковий перелік речей, які слід розглянути !!!
</li></ul>


<!--========================================================================-->
<p>
<a name="DesignSynchronization"> <br><br> </a>
<table border="1" cellpadding="5" cellspacing="0" width="100%">
<tbody><tr><td bgcolor="#98ABCE">
<span class="heading1">Розробка паралельних програм</span></td>
</tr></tbody></table>
</p><h2>Синхронізація</h2>

<img src="./Introduction to Parallel Computing_files/sychronization2.jpg" width="300" align="right" hspace="20">
<ul>
<li>Управління послідовністю роботи та виконання завдань є критичним дизайном для більшості паралельних програм.
<p>
</p></li><li>Може бути важливим чинником ефективності програми (або його відсутності)
<p>
</p></li><li>Часто вимагає "серіалізація" сегментів програми
</li></ul>

<img src="./Introduction to Parallel Computing_files/arrowBullet.gif" align="top" hspace="3">
<span class="heading3">Типи синхронізації:</span>
<ul>
<p>
</p><li><b>Бар'єр</b>
    <ul>
    <li>Звичайно, випливає, що всі завдання беруть участь
    </li><li>Кожне завдання виконує свою роботу до досягнення бар'єру. Потім він зупиняється або "блокується".        
    </li><li>Коли останнє завдання досягає бар'єру, всі завдання синхронізуються.
    </li><li>Те, що відбувається від цього, змінюється. Часто робиться серійний розділ роботи. В інших випадках завдання автоматично відпускаються для продовження роботи.  
    </li></ul>
<p>
</p></li><li><b>Замок / семафор</b>
    <ul>
    <li>Можна задіяти будь-яку кількість завдань
    </li><li>Зазвичай використовується для серіалізації (захисту) доступу до глобальних даних або розділу коду. Тільки одне завдання одночасно може використовувати (власний) замок / семафор / прапор.
    </li><li>Перше завдання придбання блокування "встановлює" його. Це завдання може безпечно (серійно) отримати доступ до захищених даних або коду.
    </li><li>Інші завдання можуть намагатися набувати замок, але слід зачекати, поки завдання, яке належить блоку, не виключає його.
    </li><li>Можна блокувати або не блокувати
    </li></ul>
<p>
</p></li><li><b>Синхронні операції зв'язку</b>
    <ul>
    <li>Включає лише ті завдання, що виконують операцію зв'язку
    </li><li>Коли завдання виконує операцію зв'язку, потрібна певна форма координації з іншим завданням, що беруть участь у спілкуванні. Наприклад, перед тим, як завдання може виконати операцію відправки, вона спочатку повинна отримати підтвердження від приймаючої задачі, що його потрібно надіслати.
    </li><li>Обговорювалося раніше в розділі "Повідомлення".
    </li></ul>
</li></ul>


<!--========================================================================-->
<p>
<a name="DesignDependencies"> <br><br> </a>
<table border="1" cellpadding="5" cellspacing="0" width="100%">
<tbody><tr><td bgcolor="#98ABCE">
<span class="heading1">Розробка паралельних програм</span></td>
</tr></tbody></table>
</p><h2>Залежності даних</h2>

<img src="./Introduction to Parallel Computing_files/dependencies1.jpg" align="right" hspace="20">
<img src="./Introduction to Parallel Computing_files/arrowBullet.gif" align="top" hspace="3">
<span class="heading3">Визначення:</span>
<ul>
<p>
</p><li>A <b><i>Залежність</i></b> існує між операторами програми , коли порядок виконання інструкції впливає на результати програми. 
<p>
</p></li><li>A <b><i>Залежність даних</i></b> виникає в результаті багаторазового використання одного і того ж місця (місць) в сховище з допомогою різних завдань.
</p></li><li>Залежність важлива для паралельного програмування, оскільки вони є одним з первинних інгібіторів паралелізму.
</li></ul>
<p>

<img src="./Introduction to Parallel Computing_files/arrowBullet.gif" align="top" hspace="3">
<span class="heading3">Приклади:</span>
</p><p>
</p><ul>
<li><b>Петля здійснює залежність даних</b>
<p>
<table border="1" cellspacing="0" cellpadding="5">
<tbody><tr valign="top">
<td><pre><b>
DO J = MYSTART,MYEND
   A(J) = A(J-1) * 2.0
END DO
</b></pre></td>
</tr></tbody></table>
</p><p>
    Значення A (J-1) повинно бути обчислено до значення A (J), тому A (J) виявляє залежність даних від A (J-1). Паралелізм гальмується.
</p><p> Якщо завдання 2 має A (J) і завдання 1 має A (J-1), обчислення правильного значення A (J) вимагає: 
    </p><ul type="circle">
    <li>Архітектура розподіленої пам'яті - задача 2 повинна отримати значення A (J-1) від завдання 1 після виконання завдання 1 для його обчислення
    </li><li>Архітектура спільної пам'яті. Завдання 2 має прочитати A (J-1) після завдання 1 оновлює його
    </li></ul>
<p>
</p></li><li><b>Незалежна залежність даних від циклу</b>
<p>
<table border="1" cellspacing="0" cellpadding="5">
<tbody><tr valign="top">
<td><pre><b>
Завдання 1        завдання 2
------        	    ------

X = 2               X = 4
  .                   .
  .                   .
Y = X**2           Y = X**3
</b></pre></td>
</tr></tbody></table>
</p><p>
    Як і в попередньому прикладі, паралелізм гальмується. Значення Y залежить від:
    </p><ul type="circle">
    <li>Архітектура розподіленої пам'яті - якщо або коли значення X передається між завданнями. 
    </li><li>Архітектура спільної пам'яті - останнє завдання, яке зберігає значення X.
    </li></ul>
<p>
</p></li><li>Хоча всі залежнощі даних важливі для ідентифікації під час розробки паралельних програм, залежно від виконання циклів є особливо важливими, оскільки цикли є, можливо, найпоширенішою метою процесу розпаралелювання.

</li></ul>
<p>

<img src="./Introduction to Parallel Computing_files/arrowBullet.gif" align="top" hspace="3">
<span class="heading3">Як керувати залежностями даних:</span>
</p><ul>
<p>
</p><li>Розподілені архітектури пам'яті - передача необхідних даних в точках синхронізації.
<p>
</p></li><li>Архітектура спільної пам'яті - синхронізація операцій читання / запису між завданнями. 
</li></ul>


<!--========================================================================-->
<p>
<a name="DesignLoadBalance"> <br><br> </a>
<table border="1" cellpadding="5" cellspacing="0" width="100%">
<tbody><tr><td bgcolor="#98ABCE">
<span class="heading1">Розробка паралельних програм</span></td>
</tr></tbody></table>
</p><h2>Балансування навантаження</h2>

<ul>
<p>
</p><li>Балансування навантаження стосується практики розподілу приблизно однакових обсягів робіт серед завдань, щоб  <b><i>всі</i></b> завдання були постійно зайняті <b><i>весь</i></b> час. Це можна вважати мінімізацією часу простою завдання.
<p>
</p></li><li>Балансування навантаження важливе для паралельних програм з міркувань продуктивності. Наприклад, якщо для всіх завдань підлягає точка синхронізації бар'єру, повільне завдання визначатиме загальну продуктивність.
<p>
<table border="0" cellpadding="0" cellspacing="0">
<tbody><tr valign="top">
<td><img src="./Introduction to Parallel Computing_files/load_bal1.gif" width="403" height="188"></td>
<td><img src="./Introduction to Parallel Computing_files/loadImbalance2.jpg" height="188" hspace="50"></td>
</tr></tbody></table>
</p><p>
</p></li></ul>

<img src="./Introduction to Parallel Computing_files/arrowBullet.gif" align="top" hspace="3">
<span class="heading3">Як досягти балансу завантаження</span>
<ul>
<p>
</p><li><b>Кожне завдання одержує рівну частину роботи</b>
    <ul>
    <li>Для операцій масиву / матриці, де кожне завдання виконує подібну роботу, рівномірно розподіляють набір даних серед завдань.
    </li><li>Для ітерацій циклу, де робота, виконана у кожній ітерації, аналогічна, рівномірно розподіляють ітерації по задачам.
    </li><li>Якщо використовується неоднорідна суміш машин з різними характеристиками продуктивності, обов'язково використовуйте який-небудь тип інструмента аналізу продуктивності для виявлення будь-якого дисбалансу навантаження. Відрегулюйте роботу відповідно.
    </li></ul><p>
</p></li><li><b>Використовуйте динамічне робоче завдання</b>
    <ul>
    <li>Деякі класи проблем призводять до дисбалансу навантаження, навіть якщо дані рівномірно розподілені між завданнями:
<p>
<table border="0" cellspacing="0" cellpadding="5" width="90%">
<tbody><tr valign="top">
<td width="33%"><img src="./Introduction to Parallel Computing_files/sparseMatrix.gif" height="250"></td>
<td width="33%"><img src="./Introduction to Parallel Computing_files/adaptiveGrid.jpg" height="250"></td>
<td width="33%"><img src="./Introduction to Parallel Computing_files/n-body.jpg" height="230" vspace="10"></td>
</tr><tr valign="top">
<td>Розгалужені масиви - деякі завдання матимуть фактичні дані для роботи, тоді як інші мають в основному «нулі».</td>
<td>Методи адаптивної сітки - для деяких завдань може знадобитися поліпшити їх сітку, а інших - ні.</td>
<td><i>N</i>-body simulations - частинки можуть мігрувати між доменами задач, що потребують більшої роботи для виконання деяких завдань.
</td>
</tr></tbody></table>
</p><p>
    </p></li><li>Коли обсяг роботи кожної задачі виконуватиметься навмисно змінено або неможливо передбачити, може бути корисно застосувати підхід до набору <b><i>планувальника</i></b>. Коли кожне завдання закінчує свою роботу, він отримує нову частину з черги роботи.
<p>
<img src="./Introduction to Parallel Computing_files/schedulerTaskPool.gif">
</p><p>
    </p></li><li>Зрештою, може стати необхідним розробляти алгоритм, який визначає і управляє дисбалансом навантаження, оскільки він відбувається динамічно в межах коду.
    </li></ul>
</li></ul>


<!--========================================================================-->
<p>
<a name="DesignGranularity"> <br><br> </a>
<table border="1" cellpadding="5" cellspacing="0" width="100%">
<tbody><tr><td bgcolor="#98ABCE">
<span class="heading1">Розробка паралельних програм</span></td>
</tr></tbody></table>
</p><h2>Гранулярність</h2>

<img src="./Introduction to Parallel Computing_files/arrowBullet.gif" align="top" hspace="3">
<span class="heading3">Обчислення / коефіцієнт зв'язку:</span>
<ul>
<p>
</p><li>При паралельних обчисленнях деталізація є якісною мірою співвідношення обчислень до комунікації.
<p>
</p></li><li>Періоди обчислення, як правило, відокремлюються від періодів спілкування по подій синхронізації.
</li></ul>
<p>

<img src="./Introduction to Parallel Computing_files/arrowBullet.gif" align="top" hspace="3">
<span class="heading3">Дрібнозернисті паралелізм:</span>
</p><p>
<table border="0" cellpadding="0" cellspacing="0">
<tbody><tr valign="top">
<td> <ul> 
     <p>
     </p><li>Порівняно невеликі обсяги обчислювальних робіт виконуються між подій зв'язку 
     <p>
     </p></li><li>Низькі обчислення до співвідношення зв'язку 
     <p>
     </p></li><li>Сприяє збалансуванню навантаження
     <p>
     </p></li><li>Мається на увазі високі комунікаційні витрати та менша можливість для підвищення продуктивності
     <p>
     </p></li><li>Якщо деталізація занадто добре, можливо, що накладні витрати, необхідні для зв'язку та синхронізації між завданнями, тривають довше, ніж обчислення. 
     </li></ul>
<p>

<img src="./Introduction to Parallel Computing_files/arrowBullet.gif" align="top" hspace="3">
<span class="heading3">Паралелізм грубозернистості:</span>
     </p><ul>
     <p>
     </p><li>Відносно великі обсяги обчислювальних робіт виконуються між подіями зв'язку / синхронізації
     <p>
     </p></li><li>Високі обчислення до співвідношення зв'язку
     <p>
     </p></li><li>Мається на увазі більша можливість для підвищення продуктивності
     <p>
     </p></li><li>Важче ефективно завантажувати баланс
     </li></ul>
<p>

<img src="./Introduction to Parallel Computing_files/arrowBullet.gif" align="top" hspace="3">
<span class="heading3">Який найкращий?</span>
</p><ul>
<p>
</p><li>Найбільш ефективна грануляція залежить від алгоритму та апаратного середовища, в якому він працює.
<p>
</p></li><li>У більшості випадків накладні витрати, пов'язані з комунікацією та синхронізацією, є високими відносно швидкості виконання, тому перевага полягає в тому, щоб груба гранулярність була.
<p>
</p></li><li>Точний паралелізм може допомогти зменшити накладні витрати через незбалансованість навантаження.
</li></ul></td>
<td><img src="./Introduction to Parallel Computing_files/granularity2.gif" align="right" hspace="20">
<img src="./Introduction to Parallel Computing_files/granularity3.gif" align="right" hspace="20" vspace="30"></td>
</tr></tbody></table>

<!--========================================================================-->

<a name="DesignIO"> <br><br> </a>
<table border="1" cellpadding="5" cellspacing="0" width="100%">
<tbody><tr><td bgcolor="#98ABCE">
<span class="heading1">Розробка паралельних програм</span></td>
</tr></tbody></table>
</p><h2>I/O</h2>

<img src="./Introduction to Parallel Computing_files/memoryAccessTimes.gif" width="555" height="258" align="right" hspace="25">
<img src="./Introduction to Parallel Computing_files/arrowBullet.gif" align="top" hspace="3">
<span class="heading3">Погані новини:</span>
<p>
</p><ul>
<li>Операції введення-виведення, як правило, розглядаються як інгібітори паралелізму.
<p>
</p></li><li>Операції введення-виведення потребують набагато більше часу, ніж операції пам'яті.
<p>
</p></li><li>Паралельні системи вводу-виводу можуть бути незрілими або недоступними для всіх платформ.
<p>
</p></li><li>У середовищі, де всі завдання мають однакове розміщення файлів, операції запису можуть призвести до перезапису файлів.
<p>
</p></li><li>Функція читання може впливати на спроможність файлового сервера обробляти декілька запитів для читання одночасно.
<p>
</p></li><li>Введення / виводу, яке повинно проводитись через мережу (NFS, не локальне), може спричинити серйозні вузькі місця та навіть збій файлових серверів.
</li></ul>
<p>

<img src="./Introduction to Parallel Computing_files/arrowBullet.gif" align="top" hspace="3">
<span class="heading3">Добрі новини:</span>
</p><ul>
<p>
</p><li>Паралельні файлові системи доступні. Наприклад:
    <ul>
    <li>GPFS: загальна паралельна файлова система (IBM). Тепер називається спектромова шкала IBM.
    </li><li>Lustre: для кластерів Linux (Intel)
    </li><li>HDFS: розподілена файлова система Hadoop (Apache)
    </li><li>PanFS: Panasas ActiveScale файлова система для кластерів Linux (Panasas, Inc.)
    </li><li>І ще - див.      
<a href="http://en.wikipedia.org/wiki/List_of_file_systems#Distributed_parallel_file_systems" target="_blank">http://en.wikipedia.org/wiki/List_of_file_systems#Distributed_parallel_file_systems</a>
    </li></ul>
<p>
</p></li><li>Специфікація інтерфейсу програмування для паралельного введення / виводу для MPI була доступна з 1996 року як частина MPI-2. Постачальники та "вільні" реалізації в даний час широко доступні.
<p>
</p></li><li>Кілька вказівників:
    <ul>
    <p>
    </p><li>Правило №1: максимально зменшити загальне введення / виведення
    <p>
    </p></li><li>Якщо у вас є доступ до паралельної файлової системи, використовуйте її.
    <p>
    </p></li><li>Запис великих шматків даних, а не невеликих шматочків зазвичай значно ефективніший.
    <p>
    </p></li><li>Менше, більші файли виконують краще багатьох малих файлів.
    <p>
    </p></li><li>Обмежте введення / виводу певні послідовні частини завдання, а потім використовуйте паралельне з'єднання для розповсюдження даних для паралельних завдань. Наприклад, Завдання 1 може читати вхідний файл, а потім передавати необхідні дані до інших завдань. Крім того, Завдання 1 могла виконувати операцію запису після отримання необхідних даних з усіх інших завдань.
    <p>
    </p></li><li>Сукупні операції вводу-виводу в різних задачах - замість того, щоб виконувати багато завдань введення / виводу, вони виконують декілька завдань.
     </li></ul>
</li></ul>

<!--========================================================================-->

<a name="DesignDebug"> <br><br> </a>
<table border="1" cellpadding="5" cellspacing="0" width="100%">
<tbody><tr><td bgcolor="#98ABCE">
<span class="heading1">Розробка паралельних програм</span></td>
</tr></tbody></table>
<h2>Налагодження</h2>

<ul>
<p>
</p><li>Налагодження паралельних кодів може бути надзвичайно важким, особливо, коли коди масштабуються вгору.
<p>
</p></li><li>Хороша новина полягає в тому, що є кілька чудових відладчиків, які допомагають:
    <ul>
    <li>Threaded -  pthreads та OpenMP
    </li><li>MPI
    </li><li>GPU / акселератор
    </li><li>Hybrid
    </li></ul>
<p>
</p></li><li>Користувачі Livermore Computing мають доступ до кількох паралельних налагоджувальних засобів, встановлених на кластері LC:
    <ul>
    <li>TotalView від RogueWave Software
    </li><li>DDT від Allinea
    </li><li>Інспектор від Intel
    </li><li>Інструмент аналізу трасування стеку (STAT) - локально розроблений
    </li></ul>
<p>
</p></li><li>Всі ці інструменти мають навчальну криву, пов'язану з ними - трохи більше, ніж інші.
<p>
</p></li><li>Докладнішу інформацію та інформацію про початок роботи див.
    <ul>
    <li>Веб-сторінки LC за адресою <a href="https://hpc.llnl.gov/software/development-environment-software" target="_blank">
https://hpc.llnl.gov/software/development-environment-software</a>
    </li><li>Підручник з TotalView:  <a href="https://computing.llnl.gov/tutorials/totalview/" target="_blank">https://computing.llnl.gov/tutorials/totalview/</a>
    </li></ul>
<p>
<img src="./Introduction to Parallel Computing_files/debug1.gif" width="1000" height="509">
</p></li></ul>

<!--========================================================================-->

<a name="DesignPerformance"> <br><br> </a>
<table border="1" cellpadding="5" cellspacing="0" width="100%">
<tbody><tr><td bgcolor="#98ABCE">
<span class="heading1">Розробка паралельних програм</span></td>
</tr></tbody></table>
<h2>Аналіз продуктивності та настройка</h2>

<ul>
<p>
</p><li>Як і при налагодженні, аналіз і настройка роботи паралельної програми може бути набагато складнішим, ніж для серійних програм.
<p>
</p></li><li>На щастя, існує цілий ряд відмінних інструментів для паралельного аналізу продуктивності та налаштування.
<p>
</p></li><li>Користувачі Livermore Computing мають доступ до кількох таких інструментів, більшість з яких доступні для всіх виробничих кластерів.
<p>
</p></li><li>Деякі вихідні точки для інструментів, встановлених на систем LC:
    <ul>
    <li>Веб-сторінки LC за адресою <a href="https://hpc.llnl.gov/software/development-environment-software" target="_blank">
https://hpc.llnl.gov/software/development-environment-software</a>
    </li><li>TAU:
        <a href="http://www.cs.uoregon.edu/research/tau/docs.php" target="_blank">http://www.cs.uoregon.edu/research/tau/docs.php</a>
    </li><li>HPCToolkit:
        <a href="http://hpctoolkit.org/documentation.html" target="_blank">http://hpctoolkit.org/documentation.html</a>
    </li><li>Open|Speedshop:
        <a href="http://www.openspeedshop.org/" target="_blank">http://www.openspeedshop.org/</a>
    </li><li>Vampir / Vampirtrace:
        <a href="http://vampir.eu/" target="_blank">http://vampir.eu/</a>
    </li><li>Valgrind:
        <a href="http://valgrind.org/" target="_blank">http://valgrind.org/</a>
    </li><li>PAPI:
        <a href="http://icl.cs.utk.edu/papi/" target="_blank">http://icl.cs.utk.edu/papi/</a>
    </li><li>mpitrace
        <a href="https://computing.llnl.gov/tutorials/bgq/index.html#mpitrace" target="_blank">
        https://computing.llnl.gov/tutorials/bgq/index.html#mpitrace</a>
    </li><li>mpiP:
        <a href="http://mpip.sourceforge.net/" target="_blank">http://mpip.sourceforge.net/</a>
    </li><li>memP:
        <a href="http://memp.sourceforge.net/" target="_blank">http://memp.sourceforge.net/</a>
    </li></ul>
<p>
<img src="./Introduction to Parallel Computing_files/perfAnalysis.jpg" width="981" height="627">
</p></li></ul>

<!---------------------------- Removed 5/7/14 -------------------------------------
    <LI>A dated, but potentially useful LC whitepaper on the subject of "High Performance Tools and Technologies" describes a large number of tools, and a number of performance related topics applicable to code developers. Find it at:
<A HREF=../performance_tools/HighPerformanceToolsTechnologiesLC.pdf TARGET=toolspaper>computing.llnl.gov/tutorials/performance_tools/HighPerformanceToolsTechnologiesLC.pdf</A>.
    <LI><A HREF=../performance_tools TARGET=W2>Performance 
    Analysis Tools Tutorial</A>
------------------------------ Removed 5/7/14 ------------------------------------->


<!--========================================================================-->

<a name="Examples"> <br><br> </a><a name="ExamplesArray"> </a>
<table border="1" cellpadding="5" cellspacing="0" width="100%">
<tbody><tr><td bgcolor="#98ABCE">
<span class="heading1">Паралельні приклади</span></td>
</tr></tbody></table>
<h2>Обробка масивів</h2>

<table border="0" cellpadding="0" cellspacing="0">
<tbody><tr valign="top">
<td>
<ul>
<p>
</p><li>Цей приклад демонструє розрахунки на 2-мірних елементах масиву; функція оцінюється на кожен елемент масиву.
<p>
</p></li><li>Обчислення на кожен елемент масиву незалежно від інших елементів масиву.
<p>
</p></li><li>Проблема є обчислювальною інтенсивністю.
<p>
</p></li><li>Серійна програма розраховує один елемент одночасно в послідовному порядку.
<p>
</p></li><li>Серійний код може мати форму:
<p>
<table border="1" cellpadding="5" cellspacing="0">
<tbody><tr><td><pre><b>
do j = 1,n
  do i = 1,n
    a(i,j) = fcn(i,j)
  end do
end do

</b></pre>
</td></tr></tbody></table>
</p><p>
</p></li><li>Питання для запитання:
<ul>
<li>Чи можна розпаралелювати цю проблему?
</li><li>Як буде розбита проблема?
</li><li>Чи потрібні комунікації?
</li><li>Чи існують які-небудь дані залежностей?
</li><li>Чи потрібна синхронізація?
</li><li>Чи буде балансування навантаження бути проблемою?
</li></ul>
</li></ul>
</td>
<td>
<img src="./Introduction to Parallel Computing_files/array_proc1.gif" width="297" height="369" hspace="20">
</td>
</tr></tbody></table>


<p></p><hr><p>
</p><h2>Паралельне рішення <br>обробки масивів 1</h2>

<ul>
<p>
<img src="./Introduction to Parallel Computing_files/array_proc2.gif" width="297" height="247" hspace="20" align="right">
</p><li>Розрахунок елементів незалежно один від одного - призводить до незрозуміло паралельного рішення.
<p>
</p></li><li>Елементи масиву рівномірно розподілені таким чином, що кожен процес володіє частиною масиву (subarray).
<ul>
<p>
</p><li>Схема розподілу вибирається для ефективного доступу до пам'яті; наприклад, одиничний кроком (кроком 1) через сусіди. Stride одиниці максимізує використання кеша / пам'яті.
<p>
</p></li><li>Оскільки бажано пройти одиницю через субари, вибір схеми розподілу залежить від мови програмування. Див. <a href="https://computing.llnl.gov/tutorials/parallel_comp/#distributions"> Діаграму блок-циклічних розподілів</a>
    для параметрів.
</li></ul>
<p>
</p></li><li>Незалежний розрахунок елементів масиву забезпечує відсутність необхідності спілкування або синхронізації завдань.
<p>
</p></li><li>Оскільки обсяг робіт рівномірно розподіляється між процесами, не повинно бути проблем з навантаженням.
<p>
</p></li><li>Після розповсюдження масиву кожне завдання виконує частину циклу, відповідну до даних, якими вона володіє. 
Наприклад, показано розподіл блоків як Fortran (column-major), так і C (row-major).
<p>
<table border="1" cellpadding="5" cellspacing="0">
<tbody><tr valign="top">
<td width="50%"><pre><b>
do j = <font color="red">mystart, myend</font>
  do i = 1, n
    a(i,j) = fcn(i,j)
  end do
end do

</b></pre></td>
<td width="50%"><pre><b>
for i (i = <font color="red">mystart</font>; i &lt; <font color="red">myend</font>; i++) {
  for j (j = 0; j &lt; n; j++) {
    a(i,j) = fcn(i,j);
    }
  }

</b></pre></td>
</tr></tbody></table>
</p><p>
</p></li><li>Зверніть увагу, що лише змінні зовнішнього циклу відрізняються від серійного рішення.
</li></ul>
<p>

<img src="./Introduction to Parallel Computing_files/arrowBullet.gif" align="top" hspace="3">
<span class="heading3">Одне з можливих рішень:</span>
</p><ul>
<p>
</p><li>Впровадити в якості моделі єдиної програми кількох даних (SPMD) - кожне завдання виконує ту ж програму.
<p>
</p></li><li>Майстер-процес ініціалізує масив, передає інформацію робочим процесам і отримує результати.
<p>
</p></li><li>Робочий процес отримує інформацію, виконує свою частку обчислень і відправляє результати для оволодіння.
<p>
</p></li><li>Використовуючи схему зберігання Fortran, виконуйте блоковий розподіл масиву.
<p>
</p></li><li>Псевдокодове рішення:
    <b><font color="red">червоний</font></b> виділяє зміни для паралелізму.
<p>
<table border="1" cellpadding="5" cellspacing="0">
<tbody><tr><td><pre><b><font color="red">
find out if I am MASTER or WORKER
   
if I am MASTER
   
  initialize the array
  send each WORKER info on part of array it owns
  send each WORKER its portion of initial array
   
  receive from each WORKER results 
   
else if I am WORKER
  receive from MASTER info on part of array I own
  receive from MASTER my portion of initial array
</font>
  # calculate my portion of array
  do j = <font color="red">my first column,my last column </font>
    do i = 1,n
      a(i,j) = fcn(i,j)
    end do
  end do
<font color="red">
  send MASTER results 

endif
</font></b></pre>
</td></tr></tbody></table>
</p></li></ul>
<p>

<img src="./Introduction to Parallel Computing_files/arrowBullet.gif" align="top" hspace="3">
<span class="heading3">Приклади програм:</span>
</p><ul>
<li>Програма MPI в C: &nbsp;
<font size="-1"><b><input type="button" value="mpi_array.c" onclick="popUp(&#39;../mpi/samples/C/mpi_array.c&#39;)"></b></font>
<p>
</p></li><li>Програма MPI в Фортран: &nbsp;
<font size="-1"><b><input type="button" value="mpi_array.f" onclick="popUp(&#39;../mpi/samples/Fortran/mpi_array.f&#39;)"></b></font>
</li></ul>

<p></p><hr><p>
</p><h2>Parallel Solution 2:<br>обробка масивів завдань</h2>

<ul>
<p>
</p><li>У попередньому рішенні масиву показано статичне балансування навантаження: 
    <ul>
    <li>Кожне завдання має виконувати фіксовану кількість робіт 
    </li><li>Може бути значним часом простою для більш швидких або більш легко завантажених процесорів - найповільніші завдання визначають загальну продуктивність.
    </li></ul>
<p>
</p></li><li>Статичне балансування навантаження зазвичай не є основним завданням, якщо всі завдання виконують однакову кількість роботи на однакових машинах. 
<p>
</p></li><li>Якщо у вас є проблема балансу навантаження (деякі завдання працюють швидше, ніж інші), ви можете скористатися схемою "пул завдань".
</li></ul>
<p>

<img src="./Introduction to Parallel Computing_files/arrowBullet.gif" align="top" hspace="3">
<span class="heading3">Схема пулу завдань:</span>
</p><p>
</p><ul>
<p>
</p><li>Використовуються два процеси
<p>
Магістерський процес: 
    </p><ul type="circle">
    <li>Тримає пул завдань для працівників процесів зробити
    </li><li>Відправляє працівника завдання за запитом
    </li><li>Збирає результати працівників
    </li></ul>
<p>
Робочий процес: багаторазово робить наступне
    </p><ul type="circle">
    <li>Отримує завдання від майстер-процесу
    </li><li>Виконає обчислення
    </li><li>Відправляє результати майстеру
    </li></ul>
<p>
</p></li><li>Робочі процеси не знають перед виконанням, яку частину масиву вони оброблятимуть, або скільки завдань вони виконають.
<p>
</p></li><li>Динамічне завантаження балансу відбувається під час виконання: швидше завданням буде потрібно більше роботи.    
<p>
</p></li><li>Псевдокодове рішення:
    <font color="red"><b>червоний</b></font> виділяє зміни для паралелізму.
<p>
<table border="1" cellpadding="5" cellspacing="0">
<tbody><tr><td><pre><b><font color="red">
find out if I am MASTER or WORKER

if I am MASTER

  do until no more jobs
    if request send to WORKER next job
    else receive results from WORKER
  end do

else if I am WORKER

  do until no more jobs
    request job from MASTER
    receive from MASTER next job
</font>
    calculate array element: a(i,j) = fcn(i,j)
<font color="red">
    send results to MASTER
  end do

endif
</font>
</b></pre>
</td></tr></tbody></table>
</p></li></ul>
<p>

<img src="./Introduction to Parallel Computing_files/arrowBullet.gif" align="top" hspace="3">
<span class="heading3">Обговорення:</span>
</p><ul>
<p>
</p><li>Наприклад, у наведеному вище пулі завдань кожне завдання розрахувало окремий елемент масиву як завдання. Обчислення до коефіцієнта зв'язку є дрібно гранульованим.
<p>
</p></li><li>Дрібно гранульовані рішення потребують додаткових витрат на зв'язок, щоб зменшити час простою роботи.
<p>
</p></li><li>Більш оптимальним рішенням може бути поширення більше роботи з кожною роботою. "Правильний" обсяг роботи залежить від проблеми.
</li></ul>


<!--========================================================================-->

<a name="ExamplesPI"> <br><br> </a>
<table border="1" cellpadding="5" cellspacing="0" width="100%">
<tbody><tr><td bgcolor="#98ABCE">
<span class="heading1">Паралельні приклади</span></td>
</tr></tbody></table>
<h2>Розрахунок PI</h2> 

<table border="0" cellspacing="0" cellpadding="0">
<tbody><tr valign="top">
<td>
<ul>
<li>Значення PI може бути розраховане різними способами. Розглянемо метод Монте-Карло для наближення PI:
<ul> 
<li>Вставте колі з радіусом <b>r</b> в квадрат із довжиною сторони <b>2<i>p</i></b> 
</li><li>Площа окружності становить <b>Πr<sup>2</sup></b> площа квадрата <b>4r<sup>2</sup></b> 
</li><li>Співвідношення площі кола до площі квадрата становить: <br><b>Πr<sup>2</sup> / 4r<sup>2</sup> = Π / 4</b> 
</li><li>Якщо ви довільно генеруєте <b>N</b> балів усередині квадрата, приблизно <br><b>N * Π / 4</b> цих точок (<b>M</b>) повинно потрапляти всередину кола. </li><li><b>Π</b> потім аппроксиміруется як:  
<br><b>N * Π / 4 = M 
<br>Π / 4 = M / N 
<br>Π = 4 * M / N</b> 
</li><li>Зверніть увагу, що збільшення кількості отриманих балів покращує наближення.
</li></ul>
<p>
</p></li><li>Послідовний псевдокод для цієї процедури:
<p>
<table border="1" cellpadding="5" cellspacing="0">
<tbody><tr><td><pre><b>
npoints = 10000
circle_count = 0

do j = 1,npoints
  generate 2 random numbers between 0 and 1
  xcoordinate = random1
  ycoordinate = random2
  if (xcoordinate, ycoordinate) inside circle
  then circle_count = circle_count + 1
end do

PI = 4.0*circle_count/npoints

</b></pre>
</td></tr></tbody></table>


</p><p>
</p></li><li>Проблема є обчислювальною інтенсивністю - більша частина часу витрачається на виконання циклу
<p>
</p></li><li>Питання для запитання:
<ul>
<li>Чи можна розпаралелювати цю проблему?
</li><li>Як буде розбита проблема?
</li><li>Чи потрібні комунікації?
</li><li>Чи існують які-небудь дані залежностей?
</li><li>Чи потрібна синхронізація?
</li><li>Чи буде балансування навантаження бути проблемою?
</li></ul>
</li></ul>
</td>
<td>
<img src="./Introduction to Parallel Computing_files/pi1.gif" width="400" height="517" hspace="20">
</td></tr></tbody></table>


<p></p><hr><p>
</p><h2>PI розрахунок<br>паралельних рішень</h2>

<table border="0" cellspacing="0" cellpadding="0">
<tbody><tr valign="top">
<td>
<ul>
<p>
</p><li>Інша проблема, яку легко розпаралелювати:
<ul>
<li>Всі точні розрахунки незалежні; немає залежностей даних
</li><li>Робота може бути розподілена рівномірно; немає проблем із завантаженням вантажу
</li><li>Немає необхідності спілкування або синхронізації між завданнями
</li></ul>
<p>
</p></li><li>Паралельна стратегія:
<ul>
<li>Розділіть цикл на рівних частинах, які можуть бути виконані пулом завдань
</li><li>Кожне завдання самостійно виконує свою роботу
</li><li>Використовується модель SPMD
</li><li>Одне завдання виконує роль майстра для збору результатів та обчислення значення PI
</li></ul>
<p>
</p></li><li>Псевдокодове рішення:
    <font color="red"><b>червоний</b></font> виділяє зміни для паралелізму.
<p>
<table border="1" cellpadding="5" cellspacing="0">
<tbody><tr><td><pre><b>
npoints = 10000
circle_count = 0
<font color="red">
p = number of tasks
num = npoints/p

find out if I am MASTER or WORKER </font>

do j = 1,<font color="red">num </font>
  generate 2 random numbers between 0 and 1
  xcoordinate = random1
  ycoordinate = random2
  if (xcoordinate, ycoordinate) inside circle
  then circle_count = circle_count + 1
end do
<font color="red">
if I am MASTER

  receive from WORKERS their circle_counts
  compute PI (use MASTER and WORKER calculations)

else if I am WORKER

  send to MASTER circle_count

endif
</font>
</b></pre>
</td></tr></tbody></table>
</p></li></ul>
</td>
<td>
<img src="./Introduction to Parallel Computing_files/pi2.gif" width="400" height="475" hspace="20">
</td></tr></tbody></table>

<p>

<img src="./Introduction to Parallel Computing_files/arrowBullet.gif" align="top" hspace="3">
<span class="heading3">Приклади програм:</span>
</p><ul>
<li>Програма MPI в C: &nbsp;
<font size="-1"><b><input type="button" value="mpi_pi_reduce.c" onclick="popUp(&#39;../mpi/samples/C/mpi_pi_reduce.c&#39;)"></b></font>
<p>
</p></li><li>Програма MPI в Фортран: &nbsp;
<font size="-1"><b><input type="button" value="mpi_pi_reduce.f" onclick="popUp(&#39;../mpi/samples/Fortran/mpi_pi_reduce.f&#39;)"></b></font>
</li></ul>

<!--========================================================================-->

<a name="ExamplesHeat"> <br><br> </a>
<table border="1" cellpadding="5" cellspacing="0" width="100%">
<tbody><tr><td bgcolor="#98ABCE">
<span class="heading1">Паралельні приклади</span></td>
</tr></tbody></table>
<h2>Simple Heat Equation</h2>

<table border="0" cellspacing="0" cellpadding="0">
<tbody><tr valign="top">
<td><ul>
<p>
</p><li>Більшість проблем паралельних обчислень вимагають спілкування між завданнями. Ряд спільних проблем вимагає спілкування з "сусідами" завдань.
<p>
</p></li><li>2-D рівняння теплопровідності описує зміну температури з плином часу, з урахуванням початкового розподілу температури та граничних умов.
<p>
</p></li><li>Для розв'язання рівняння теплопути на квадратній ділянці застосовується скінченна диференційована схема.
<ul>
<li>Елементи 2-мірного масиву представляють температуру в точках на квадраті.
</li><li>Початкова температура дорівнює нулю на кордонах і висока в середині.
</li><li>Гранична температура зберігається в нулі.
</li><li>Використовується алгоритм з часом.
</li></ul>
<p>
</p></li><li>Розрахунок елемента <b><i>залежить</i></b> від значень сусідніх елементів:
    values:
<p>
<img src="./Introduction to Parallel Computing_files/heat_equation2.gif" width="276" height="114">
</p><p>
</p></li><li>Серійна програма міститиме код, такий як:
<p>
<table border="1" cellpadding="5" cellspacing="0">
<tbody><tr><td><pre><b>
do iy = 2, ny - 1
  do ix = 2, nx - 1
    u2(ix, iy) =  u1(ix, iy)  +
        cx * (u1(ix+1,iy) + u1(ix-1,iy) - 2.*u1(ix,iy)) +
        cy * (u1(ix,iy+1) + u1(ix,iy-1) - 2.*u1(ix,iy))
  end do
end do
</b></pre>
</td></tr></tbody></table>
</p><p>
</p></li><li>Питання для запитання:
<ul>
<li>Чи можна розпаралелювати цю проблему?
</li><li>Як буде розбита проблема?
</li><li>Чи потрібні комунікації?
</li><li>Чи існують які-небудь дані залежностей?
</li><li>Чи потрібна синхронізація?
</li><li>Чи буде балансування навантаження бути проблемою? 
</li></ul>
</li></ul></td>

<td><img src="./Introduction to Parallel Computing_files/heat_initial.gif" width="300" height="301" hspace="20">

<img src="./Introduction to Parallel Computing_files/heat_equation.gif" width="261" height="258" border="0" hspace="20" vspace="20" alt="Heat equation">
</td></tr></tbody></table>

<p></p><hr><p>
</p><h2>Просте паралельне рішення<br>рівняння тепла</h2>
<p>

<img src="./Introduction to Parallel Computing_files/heat_partitioned.gif" width="300" height="301" align="right" hspace="20">
</p><ul>
<p>
</p><li>Ця проблема є складнішою, оскільки існує залежність даних, яка вимагає зв'язку та синхронізації.
<p>
</p></li><li>Весь масив розподіляється і розподіляється як сумарний для всіх завдань. Кожне завдання володіє рівною частиною всього масиву.
<p>
</p></li><li>Оскільки обсяг роботи однаковий, балансування навантаження не повинно бути проблемою
<p>
</p></li><li>Визначення залежностей даних:
    <ul>
    <li><a href="https://computing.llnl.gov/tutorials/parallel_comp/images/heat_interior.gif" target="W6">елементи інтер'єру</a> що належать до завдання, не залежать від інших завдань
    </li><li><a href="https://computing.llnl.gov/tutorials/parallel_comp/images/heat_edge.gif" target="W7">прикордонні елементи</a> залежать від даних сусіда, що вимагають зв'язку.
    </li></ul>
<p>
</p></li><li>Впровадити як модель SPMD:
<ul>
<li>Майстерський процес надсилає первинну інформацію працівникам, а потім чекає, щоб збирати результати від усіх працівників
</li><li>Робочі процеси розраховують рішення в задану кількість етапів часу, спілкуючись, коли це необхідно, з сусідніми процесами
</li></ul>
<p>
</p></li><li>Псевдокодове рішення:
    <font color="red"><b>червоний</b></font> виділяє зміни для паралелізму.
<p>
<table border="1" cellpadding="5" cellspacing="0">
<tbody><tr><td><pre><b><font color="red">
find out if I am MASTER or WORKER

if I am MASTER
  initialize array
  send each WORKER starting info and subarray
  receive results from each WORKER

else if I am WORKER
  receive from MASTER starting info and subarray
</font>
  # Perform time steps
  do t = 1, nsteps
    update time <font color="red">
    send neighbors my border info
    receive from neighbors their border info </font>
    update my portion of solution array
    
  end do
  <font color="red">
  send MASTER results
      
endif
</font>
</b></pre>
</td></tr></tbody></table>
</p></li></ul>
<p>

<img src="./Introduction to Parallel Computing_files/arrowBullet.gif" align="top" hspace="3">
<span class="heading3">Приклади програм:</span>
</p><ul>
<li>Програма MPI в C: &nbsp;
<font size="-1"><b><input type="button" value="mpi_heat2D.c" onclick="popUp(&#39;../mpi/samples/C/mpi_heat2D.c&#39;)"></b></font>
<p>
</p></li><li>Програма MPI в Фортран: &nbsp;
<font size="-1"><b><input type="button" value="mpi_heat2D.f" onclick="popUp(&#39;../mpi/samples/Fortran/mpi_heat2D.f&#39;)"></b></font>
</li></ul>

<!-----------------------------------------------------------------------

<P><HR><P> 
<H2>Simple Heat Equation<BR>
Parallel Solution 2: Overlapping Communication and Computation</H2>

<UL>
<P>
<LI>In the previous solution, it was assumed that blocking communications
    were used by the worker tasks.  Blocking communications wait for the 
    communication process to complete before continuing to the next 
    program instruction.
<P>
<LI>In the previous solution, neighbor tasks communicated border
    data, then each process updated its portion of the array.
<P>
<LI>Computing times can often be reduced by using non-blocking
    communication.  Non-blocking communications allow work to be performed 
    while communication is in progress.
<P>
<LI>Each task could update the interior of its part of the solution
    array while the communication of border data is occurring, and
    update its border after communication has completed.
<P>
<LI>Pseudo code for the second solution:
    <FONT COLOR=red><B>red</B></FONT COLOR> highlights changes for 
    non-blocking communications.
<P>
<TABLE BORDER=1 CELLPADDING=5 CELLSPACING=0>
<TR><TD><PRE><B>
find out if I am MASTER or WORKER
 
if I am MASTER
  initialize array
  send each WORKER starting info and subarray
    
  do until all WORKERS converge
    gather from all WORKERS convergence data
    broadcast to all WORKERS convergence signal
  end do
 
  receive results from each WORKER
 
else if I am WORKER
  receive from MASTER starting info and subarray
 
  do until solution converged
    update time
    <FONT COLOR=red>
    non-blocking send neighbors my border info
    non-blocking receive neighbors border info

    update interior of my portion of solution array
    wait for non-blocking communication complete
    update border of my portion of solution array
    </FONT>
    determine if my solution has converged
      send MASTER convergence data
      receive from MASTER convergence signal
  end do
  
  send MASTER results
       
endif

</B></PRE>
</TD></TR></TABLE>
</UL>
------------------------------------------------------------------------>

<!--========================================================================-->

<a name="ExamplesWave"> <br><br> </a>
<table border="1" cellpadding="5" cellspacing="0" width="100%">
<tbody><tr><td bgcolor="#98ABCE">
<span class="heading1">Паралельні приклади</span></td>
</tr></tbody></table>
<h2>1-D хвильове рівняння</h2>

<ul>
<p>
</p><li>У цьому прикладі амплітуда вздовж рівномірної вібраційної струни обчислюється після того, як пройшло певну кількість часу.
<p>
</p></li><li>Розрахунок передбачає:
    <ul>
    <li>амплітуда на осі y
    </li><li>i як індекс позиції вздовж осі x
    </li><li>вузлові точки, накладені вздовж струни
    </li><li>оновлення амплітуди на дискретних етапах часу.
    </li></ul>
<p>
<img src="./Introduction to Parallel Computing_files/wave3.gif">
</p><p>
</p></li><li>Рівняння, яке потрібно вирішити, - одномірне хвильове рівняння:
<p>
<table border="1" cellpadding="5" cellspacing="0">
<tbody><tr valign="top">
<td><pre><span style="white-space: nowrap"><b>
    A(i,t+1) = (2.0 * A(i,t)) - A(i,t-1) 
        + (c * (A(i-1,t) - (2.0 * A(i,t)) + A(i+1,t))) 
</b></span></pre></td>
</tr></tbody></table>
</p><p>
де c - константа
</p><p>
</p></li><li>Зверніть увагу, що амплітуда буде залежати від попередніх кроків (t, t-1) та сусідніх точок (i-1, i + 1).  
<p>
</p></li><li>Питання для запитання:
<ul>
<li>Чи можна розпаралелювати цю проблему?
</li><li>Як буде розбита проблема?
</li><li>Чи потрібні комунікації?
</li><li>Чи існують які-небудь дані залежностей?
</li><li>Чи потрібна синхронізація?
</li><li>Чи буде балансування навантаження бути проблемою?
</li></ul>
</li></ul>

<p></p><hr><p> 
</p><h2>Паралельне рішення<br>1-D хвильового рівняння</h2>

<ul>
<p>
</p><li>Це ще один приклад проблеми із залежністю даних. Паралельне рішення передбачає зв'язок та синхронізацію.
<p>
</p></li><li>Весь амплітудний масив розподіляється і розподіляється як субарні для всіх завдань. Кожне завдання володіє рівною частиною всього масиву.
<p>
</p></li><li>Балансування навантаження: всі пункти вимагають рівної роботи, тому точки повинні бути розділені рівномірно
<p>
</p></li><li>Розбиття на блок буде розбивати роботу на кількість завдань у вигляді фрагментів, що дозволяє кожному завданням володіти переважно сусідніми точками даних.
<p>
</p></li><li>Зв'язок має відбуватися тільки на межі даних. Чим більше розмір блоку, тим менше спілкування. 
<p>
<img src="./Introduction to Parallel Computing_files/wave4.gif">

</p><p>
</p></li><li>Впровадити як модель SPMD:
<ul>
<li>Майстерський процес надсилає первинну інформацію працівникам, а потім чекає, щоб збирати результати від усіх працівників
</li><li>Робочі процеси розраховують рішення в задану кількість етапів часу, спілкуючись, коли це необхідно, з сусідніми процесами
</li></ul>
<p>
</p></li><li>Псевдокодове рішення:
    <font color="red"><b>червоний</b></font> виділяє зміни для паралелізму.
<p>
<table border="1" cellpadding="5" cellspacing="0">
<tbody><tr><td><pre><b><font color="red">
find out number of tasks and task identities

#Identify left and right neighbors
left_neighbor = mytaskid - 1
right_neighbor = mytaskid +1
if mytaskid = first then left_neigbor = last
if mytaskid = last then right_neighbor = first

find out if I am MASTER or WORKER
if I am MASTER
  initialize array
  send each WORKER starting info and subarray
else if I am WORKER`
  receive starting info and subarray from MASTER
endif
</font>
#Perform time steps <font color="red">
#In this example the master participates in calculations</font>
do t = 1, nsteps <font color="red">
  send left endpoint to left neighbor
  receive left endpoint from right neighbor
  send right endpoint to right neighbor
  receive right endpoint from left neighbor
</font>
  #Update points along line
  do i = 1, npoints
    newval(i) = (2.0 * values(i)) - oldval(i) 
    + (sqtau * (values(i-1) - (2.0 * values(i)) + values(i+1))) 
  end do

end do
<font color="red">
#Collect results and write to file
if I am MASTER
  receive results from each WORKER
  write results to file
else if I am WORKER
  send results to MASTER
endif </font>

</b></pre></td></tr></tbody></table>
</p><p>
</p></li></ul>
<p>

<img src="./Introduction to Parallel Computing_files/arrowBullet.gif" align="top" hspace="3">
<span class="heading3">Приклади програм:</span>
</p><ul>
<li>Програма MPI в C: &nbsp;
<font size="-1"><b><input type="button" value="mpi_wave.c" onclick="popUp(&#39;../mpi/samples/C/mpi_wave.c&#39;)"></b></font>
<p>
</p></li><li>Програма MPI в Фортран: &nbsp;
<font size="-1"><b><input type="button" value="mpi_wave.f" onclick="popUp(&#39;../mpi/samples/Fortran/mpi_wave.f&#39;)"></b></font>
</li></ul>


<br><br>
<p></p><hr><p>

<b>Це завершує навчальний посібник.</b>
</p><p>
<table border="0" cellpadding="0" cellspacing="0">
<tbody><tr valign="top">
<td><a href="https://computing.llnl.gov/tutorials/evaluation/index.html" target="evalForm">
    <img src="./Introduction to Parallel Computing_files/evaluationForm.gif"></a> &nbsp; &nbsp; &nbsp;</td>
<td>Будь ласка, заповніть онлайн-форму для оцінки. </td>
</tr>
</tbody></table>
</p><p>
<b>Куди ти хочеш піти зараз?</b>
</p><ul>
<li><a href="https://computing.llnl.gov/tutorials/agenda/index.html">Порядок денний</a>
</li><li><a href="https://computing.llnl.gov/tutorials/parallel_comp/#top">Перейти до початку сторінки</a>
</li></ul>

<!--========================================================================-->

<a name="References"> <br><br> </a>
<table border="1" cellpadding="5" cellspacing="0" width="100%">
<tbody><tr><td bgcolor="#98ABCE">
<span class="heading1">Довідники та додаткова інформація</span></td>
</tr></tbody></table>

<ul>
<li>Автор: <a href="mailto:blaiseb@llnl.gov">Блейз Барні</a>,  Лівермор Комп'ютинг.
<p>
</p></li><li>Пошук у WWW для "паралельного програмування" або "паралельні обчислення" дасть широкий спектр інформації.
<p>
</p></li><li>Рекомендоване читання:
    <ul>
    <li>Проектування та побудова паралельних програм". Ян Фостер. 
    <br><a href="http://www.mcs.anl.gov/~itf/dbpp/" target="_blank">
        http://www.mcs.anl.gov/~itf/dbpp/</a>
    </li><li>"Вступ до паралельних обчислень". Анант Грэма, Аншюль Гупта, Джордж Карипіс, Віпін Кумар. 
    <br><a href="http://www-users.cs.umn.edu/~karypis/parbook/" target="_blank">
        http://www-users.cs.umn.edu/~karypis/parbook/</a>
    </li><li>"Огляд недавніх суперкомп'ютерів". А. Дж. Ван дер Стин, Джек Донгара. 
    <br><a href="https://computing.llnl.gov/tutorials/parallel_comp/OverviewRecentSupercomputers.2008.pdf" target="_blank">
        OverviewRecentSupercomputers.2008.pdf</a>
    </li></ul>
<p>
</p></li><li>Фото / графіка створено автором, створеною іншими співробітниками LLNL, отриманими з джерел, не захищених авторським правом, державними або загальнодоступними джерелами (наприклад, http://commons.wikimedia.org/), або використовуються з дозволу авторів з інші презентації та веб-сторінки.
<p>
</p></li><li>Історія: ці матеріали складаються з наступних джерел, деякі з яких більше не підтримуються або недоступні:
    <ul>
    <li>Навчальні посібники розроблені для "Майстер-класу паралельного програмування SP" у Мауї високопродуктивних обчислювальних центрах.
    </li><li>Навчальні посібники, розроблені Корнельським університетським центром передових обчислень (CAC), тепер доступні в якості віртуальних семінарів Cornell за адресою:
        <a href="https://cvw.cac.cornell.edu/topics" target="_blank">https://cvw.cac.cornell.edu/topics</a>.
    </li></ul>
</li></ul>

<!------------------------------------------------------------------------>

<script language="JavaScript">PrintFooter("UCRL-MI-133316")</script><p></p><hr><span class="footer">https://computing.llnl.gov/tutorials/parallel_comp/<br>Last Modified: 05/05/2018 01:54:23 <a href="mailto:blaiseb@llnl.gov">blaiseb@llnl.gov</a><br>UCRL-MI-133316<p>This work was performed under the auspices of the U.S. Department of Energy by Lawrence Livermore National Laboratory under Contract DE-AC52-07NA27345.

<br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br>
<br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br>
<br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br>
<br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br>




</p></span></font><div class="dd-sttbtn dd-sttbtn--visible" data-stt-pos="br"></div></body></html>
